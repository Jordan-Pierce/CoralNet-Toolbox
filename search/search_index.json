{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CoralNet-Toolbox","text":"<p>The <code>CoralNet-Toolbox</code> is an unofficial codebase that can be used to augment processes associated with those on CoralNet.</p> <p>It uses\u2728<code>Ultralytics</code>\ud83d\ude80 as a  base, which is an open-source library for computer vision and deep learning built in <code>PyTorch</code>. For more information on their <code>AGPL-3.0</code> license, see here.</p> <p>The <code>toolbox</code> also uses the following to create rectangle and polygon annotations: - <code>Fast-SAM</code> - <code>RepViT-SAM</code> - <code>EdgeSAM</code> - <code>MobileSAM</code> - <code>SAM</code> - <code>AutoDistill</code>   - <code>GroundingDino</code></p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Running the following command will install the <code>coralnet-toolbox</code>, which you can then run from the command line: <pre><code># cmd\n\n# Install\npip install coralnet-toolbox\n\n# Run\ncoralnet-toolbox\n</code></pre></p> <p> </p> <p>For further instructions, see How to Install;  for information on how to use, check out the Documentation.</p>"},{"location":"#tools","title":"Tools","text":"<p>Enhance your CoralNet experience with these tools: - \u270f\ufe0f Annotate: Create annotations freely - \ud83d\udc41\ufe0f Visualize: See CoralNet and CPCe annotations superimposed on images - \ud83d\udd2c Sample: Sample patches using various methods (Uniform, Random, Stratified) - \ud83e\udde9 Patches: Create patches (points) - \ud83d\udd33 Rectangles: Create rectangles (bounding boxes) - \ud83d\udfe3 Polygons: Create polygons (instance masks) - \ud83e\uddbe SAM: Use <code>FastSAM</code>, <code>RepViT-SAM</code>, <code>EdgeSAM</code>, <code>MobileSAM</code>, and <code>SAM</code> to create polygons - \ud83e\uddea AutoDistill: Use <code>AutoDistill</code> to access <code>GroundingDINO</code> for creating rectangles - \ud83e\udde0 Train: Build local patch-based classifiers, object detection, and instance segmentation models - \ud83d\udd2e Deploy: Use trained models for predictions - \ud83d\udcca Evaluation: Evaluate model performance - \ud83d\ude80 Optimize: Productionize models for faster inferencing - \u2699\ufe0f Batch Inference: Perform predictions on multiple images, automatically - \u2194\ufe0f I/O: Import and Export annotations from / to CoralNet, Viscore, and TagLab - \ud83d\udcf8 YOLO: Import and Export YOLO datasets for machine learning</p>"},{"location":"#todo","title":"TODO","text":"<ul> <li>\ud83d\udd0d API: Get predictions from any CoralNet source model</li> <li>\ud83d\udce5 Download: Retrieve source data from CoralNet</li> <li>\ud83d\udce4 Upload: Add images and annotations to CoralNet</li> <li>\ud83d\udce6 Toolshed: Access tools from the old repository</li> </ul> Watch the Video Demos"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/Jordan-Pierce/CoralNet-Toolbox/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>CoralNet-Toolbox could always use more documentation, whether as part of the official CoralNet-Toolbox docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/Jordan-Pierce/CoralNet-Toolbox/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up CoralNet-Toolbox for local development.</p> <ol> <li> <p>Fork the CoralNet-Toolbox repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/CoralNet-Toolbox.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv CoralNet-Toolbox\n$ cd CoralNet-Toolbox/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 CoralNet-Toolbox tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/Jordan-Pierce/CoralNet-Toolbox/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install <code>CoralNet-Toolbox</code>, run this command in your terminal:</p> <pre><code>pip install coralnet-toolbox\n</code></pre> <p>This is the preferred method to install <code>CoralNet-Toolbox</code>, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install <code>CoralNet-Toolbox</code> from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/Jordan-Pierce/CoralNet-Toolbox\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#overview","title":"Overview","text":"<p>The CoralNet Toolbox is a Python application built using PyQt5 for image annotation. This guide provides instructions on how to use the application, including key functionalities and hotkeys.</p>"},{"location":"usage/#annotations","title":"Annotations","text":"<ul> <li>PatchAnnotation: Represents a patch annotation.</li> <li>RectangleAnnotation: Represents a rectangular annotation.</li> <li>PolygonAnnotation: Represents a polygonal annotation.</li> </ul>"},{"location":"usage/#computer-vision-tasks","title":"Computer Vision Tasks","text":"<ul> <li>Classification: Assign a label to an image (Patch).</li> <li>Detection: Detect objects in an image (Rectangle).</li> <li>Segmentation: Segment objects in an image (Polygon).</li> </ul>"},{"location":"usage/#main-window","title":"Main Window","text":"<p>The main window consists of several components: - Menu Bar: Contains import, export, and other actions. - Tool Bar: Contains tools for selection and annotation. - Annotation Window: Displays the image and annotations. - Label Window: Lists and manages labels. - Image Window: Displays imported images. - Confidence Window: Displays cropped images and confidence charts.</p>"},{"location":"usage/#menu-bar-actions","title":"Menu Bar Actions","text":"<ul> <li>Import:</li> <li>Import Images: Load image files.</li> <li>Import Frames: Load video frames (Currently not available).</li> <li>Import Orthomosaic: Load orthomosaic images (Currently not available).</li> <li>Import Labels (JSON): Load label data from a JSON file.</li> <li>Import Annotations (JSON): Load annotation data from a JSON file.</li> <li>Import Annotations (CoralNet): Load annotation data from a CoralNet CSV file.</li> <li>Import Annotations (Viscore): Load annotation data from a Viscore CSV file.</li> <li>Import Annotations (TagLab): Load annotation data from a TagLab JSON file.</li> <li> <p>Import Dataset: Import a YOLO dataset for machine learning (Detection, Segmentation).</p> </li> <li> <p>Export:</p> </li> <li>Export Labels (JSON): Save label data to a JSON file.</li> <li>Export Annotations (JSON): Save annotation data to a JSON file.</li> <li>Export Annotations (CoralNet): Save annotation data to a CoralNet CSV file.</li> <li>Export Annotations (Viscore): Save annotation data to a Viscore CSV file.</li> <li>Export Annotations (TagLab): Save annotation data to a TagLab JSON file.</li> <li> <p>Export Dataset: Create a YOLO dataset for machine learning (Classification, Detection, Segmentation).</p> </li> <li> <p>Sample:</p> </li> <li> <p>Sample Annotations: Automatically generate Patch annotations.</p> </li> <li> <p>CoralNet: (Currently not available)</p> </li> <li>Authenticate: Authenticate with CoralNet.</li> <li>Upload: Upload data to CoralNet.</li> <li>Download: Download data from CoralNet.</li> <li> <p>Model API: Access CoralNet model API.</p> </li> <li> <p>Machine Learning:</p> </li> <li>Merge Datasets: Merge multiple Classification datasets.</li> <li>Train Model: Train a machine learning model.</li> <li>Evaluate Model: Evaluate a trained model.</li> <li>Optimize Model: Convert model format.</li> <li>Deploy Model: Make predictions using a trained model (Classification, Detection, Segmentation).</li> <li> <p>Batch Inference: Perform batch inferences.</p> </li> <li> <p>SAM:</p> </li> <li>Deploy Predictor: Deploy EdgeSAM, MobileSAM, or SAM to use interactively (points, box); Segment Anything</li> <li>Deploy Generator: Deploy FastSAM to automatically segment the image; Segment Everything<ul> <li>Recommendation: Use the \"Use Predictor to create Polygons\", as the results are significantly better</li> </ul> </li> <li> <p>Batch Inference: Perform batch inferences.</p> </li> <li> <p>AutoDistill:</p> </li> <li>Deploy Model: Deploy a foundational model<ul> <li>Models Available: GroundingDino,</li> </ul> </li> <li>Batch Inference: Perform batch inferences.</li> </ul>"},{"location":"usage/#tool-bar","title":"Tool Bar","text":"<ul> <li>Select Tool: Select multiple annotations; move and change the size of annotations.</li> <li>Patch Tool: Add new PatchAnnotations.</li> <li>Polygon Tool: Add new PolygonAnnotations.</li> <li>Rectangle Tool: Add new RectangleAnnotations.</li> <li>SAM Tool: Use SAM model for automatic segmentation (points, box).</li> </ul>"},{"location":"usage/#annotation-window","title":"Annotation Window","text":"<ul> <li>Zoom: Use the mouse wheel to zoom in and out.</li> <li>Pan: Hold Ctrl + Right-click the mouse button to pan the image.</li> <li>Add Annotation: Click with the Left mouse button while using one of the annotation tools.</li> <li>Select Annotations:</li> <li>Ctrl + Left-Click on multiple annotations while using the select tool.</li> <li>Ctrl + Left-Click and drag to select multiple annotations while using the select tool.<ul> <li>Move Annotation: Drag a selected annotation.</li> <li>Modify Annotation: Hold Shift and drag the vertices of the selected annotation (Rectangle, Polygon).</li> <li>Resize Annotation: Hold Ctrl and Zoom in / out to increase / decrease a selected annotation's size.</li> <li>Delete Annotations: Press Ctrl + Delete to delete the selected annotations.</li> </ul> </li> </ul>"},{"location":"usage/#label-window","title":"Label Window","text":"<ul> <li>Move Label: Right-click and drag to move labels.</li> <li>Add Label: Click the \"Add Label\" button to add a new label.</li> <li>Edit Label: Click the \"Edit Label\" button to edit the selected label.</li> <li>Delete Label: Click the \"Delete Label\" button to delete the selected label.</li> </ul>"},{"location":"usage/#image-window","title":"Image Window","text":"<ul> <li>Load Image: Click on a row to load the image in the annotation window.</li> <li>Delete Annotations: Right-click on a row and select \"Delete Annotations\" to remove the image's annotations.</li> <li>Search Image: Search for an image row by typing out a search string</li> </ul>"},{"location":"usage/#confidence-window","title":"Confidence Window","text":"<ul> <li>Display Cropped Image: Shows the cropped image of the selected annotation.</li> <li>Confidence Chart: Displays a bar chart with confidence scores.</li> <li>Prediction Selection: Select a prediction from the list to change the label.</li> </ul>"},{"location":"usage/#hotkeys","title":"Hotkeys","text":"<ul> <li>Ctrl + Delete: Delete the selected annotations.</li> <li>Ctrl + W/A/S/D: Navigate through labels.</li> <li>Ctrl + Mouse Wheel: Adjust annotation size.</li> <li>Ctrl + Left/Right: Cycle through annotations.</li> <li>Ctrl + Up/Down: Cycle through images.</li> <li>End: Unselect annotation.</li> <li>Home: Untoggle all tools.</li> <li> <p>Escape: Exit the program.</p> </li> <li> <p>Machine Learning, SAM, and AutoDistill: After a model is loaded</p> </li> <li>Ctrl + 1: Make prediction on selected Patch annotation, else all in the image with Review label.</li> <li>Ctrl + 2: Make predictions using Object Detection model.</li> <li>Ctrl + 3: Make predictions using Instance Segmentation model.</li> <li>Ctrl + 4: Make predictions using FastSAM model.</li> <li> <p>Ctrl + 5: Make predictions using AutoDistill model.</p> </li> <li> <p>SAM: After a model is loaded</p> </li> <li>Space Bar: Set working area; finalize prediction.</li> <li>Left-Click: Start a box; press again to end a box.</li> <li>Ctrl + Left-Click: Add positive point.</li> <li>Ctrl + Right-Click: Add negative point.</li> </ul>"},{"location":"usage/#additional-tips","title":"Additional Tips","text":"<ul> <li>Annotation Sampling: Use the \"Sample Annotations\" action in the menu bar to automatically generate annotations.</li> <li>Transparency Control: Adjust the transparency slider in the status bar to change annotation transparency.</li> <li>Uncertainty Threshold: Modify the uncertainty threshold in the status bar to restrict predicts with low confidence.</li> <li>IoU Threshold: Adjust the IoU threshold in the status bar to filter predictions based on Intersection over Union.</li> <li>Use SAM: Use SAM with a deployed Detection or Segmentation model to create Polygons for each detected object.</li> </ul>"}]}