{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Image Classifier (Notebook)\n",
    "\n",
    "This notebook can be used to train a patch-based image classifier on the data downloaded from\n",
    "CoralNet. The data (images and annotations) must have been downloaded, and using the Annotations\n",
    " to Patches Notebook / script, made into patches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, losses, metrics\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import *\n",
    "\n",
    "from plot_keras_history import plot_history\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from faker import Faker\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"CPUs Available: \", tf.config.list_physical_devices('CPU'))\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"TPUs Available: \", tf.config.list_physical_devices('TPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_class_weights(df, mu=0.15):\n",
    "    \"\"\"\n",
    "    Compute class weights for the given dataframe.\n",
    "    \"\"\"\n",
    "    # Compute the value counts for each class\n",
    "    value_counts = df['Label'].value_counts().to_dict()\n",
    "    total = sum(value_counts.values())\n",
    "    keys = value_counts.keys()\n",
    "\n",
    "    # To store the class weights\n",
    "    class_weight = dict()\n",
    "\n",
    "    # Compute the class weights for each class\n",
    "    for key in keys:\n",
    "        score = math.log(mu * total / float(value_counts[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "\n",
    "    return class_weight\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the recall metric.\n",
    "    \"\"\"\n",
    "    # Compute the true positives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    # Compute the possible positives\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    # Compute the recall\n",
    "    r = true_positives / (possible_positives + K.epsilon())\n",
    "\n",
    "    return r\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the precision metric.\n",
    "    \"\"\"\n",
    "    # Compute the true positives\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    # Compute the predicted positives\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    # Compute the precision\n",
    "    p = true_positives / (predicted_positives + K.epsilon())\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the F1-score metric.\n",
    "    \"\"\"\n",
    "    # Compute precision and recall using the previously defined functions\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "\n",
    "    # Compute the F1-score\n",
    "    f1 = 2 * (p * r) / (p + r + K.epsilon())\n",
    "\n",
    "    return f1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Data Paths\n",
    "\n",
    "Here we'll set the path to the directory containing the data for the source we want to use.\n",
    "In this case, we're using the data downloaded from a downloaded source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_ID = str(1686)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223109037
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Root and Source directory\n",
    "ROOT = \"B://CoralNet-Toolbox/Data/\"\n",
    "SOURCE_DIR = ROOT + f\"{SOURCE_ID}/\"\n",
    "\n",
    "# Patch dataframe\n",
    "patches_df = pd.read_csv(SOURCE_DIR + \"patches.csv\", index_col=0)\n",
    "patches_df = patches_df.dropna()\n",
    "\n",
    "# Run Name\n",
    "RUN = Faker().name().replace(\" \", \"_\")\n",
    "\n",
    "# We'll also create folders in this source to hold results of the model\n",
    "MODEL_DIR = SOURCE_DIR + f\"model/{RUN}/\"\n",
    "WEIGHTS_DIR = MODEL_DIR + \"weights/\"\n",
    "LOGS_DIR = MODEL_DIR + \"logs/\"\n",
    "\n",
    "# Make the directories\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) \n",
    "os.makedirs(LOGS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data\n",
    "\n",
    "Here we'll prepare the data for training. We'll use the annotations to create a dataframe\n",
    "containing the image names and their labels. We'll then split the data into training, validation,\n",
    "and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = patches_df['Image Name'].unique()\n",
    "\n",
    "# Split the Images into training, validation, and test sets.\n",
    "# We split based on the image names, so that we don't have the same image in multiple sets.\n",
    "seed =  np.random.randint(100000)\n",
    "training_images, testing_images = train_test_split(image_names, test_size=0.35, random_state=seed)\n",
    "validation_images, testing_images = train_test_split(testing_images, test_size=0.5, random_state=seed)\n",
    "\n",
    "# Create training, validation, and test dataframes\n",
    "train = patches_df[patches_df['Image Name'].isin(training_images)]\n",
    "valid = patches_df[patches_df['Image Name'].isin(validation_images)]\n",
    "test = patches_df[patches_df['Image Name'].isin(testing_images)]\n",
    "\n",
    "# If there isn't one class sample in each train and valid\n",
    "# Keras will throw an error; hacky way of fixing this.\n",
    "if set(train['Label'].unique()) - set(valid['Label'].unique()):\n",
    "\n",
    "    # Holds one sample of each class category\n",
    "    one_sample = pd.DataFrame()\n",
    "    # Gets one sample from patches_df\n",
    "    for label in patches_df['Label'].unique():\n",
    "        sample = patches_df[patches_df['Label'] == label].sample(1)\n",
    "        one_sample = pd.concat((one_sample, sample))\n",
    "\n",
    "    train = pd.concat((one_sample, train))\n",
    "    valid = pd.concat((one_sample, valid))\n",
    "\n",
    "train.reset_index(drop=True, inplace= True)\n",
    "valid.reset_index(drop=True, inplace= True)\n",
    "test.reset_index(drop=True, inplace= True)\n",
    "\n",
    "# The number of class categories\n",
    "num_classes = len(train['Label'].unique())\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data ExLploration\n",
    "\n",
    "As a sanity check, we can see how many images are in each set, and the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223311802
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Set the same y-axis limits for all subplots\n",
    "ymin = 0\n",
    "ymax = train['Label'].value_counts().max() + 10\n",
    "\n",
    "# Plotting the train data\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(f\"Train: {len(train)} Classes: {len(train['Label'].unique())}\")\n",
    "ax = train['Label'].value_counts().plot(kind='bar')\n",
    "ax.set_ylim([ymin, ymax])\n",
    "\n",
    "# Plotting the valid data\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(f\"Valid: {len(valid)} Classes: {len(valid['Label'].unique())}\")\n",
    "ax = valid['Label'].value_counts().plot(kind='bar')\n",
    "ax.set_ylim([ymin, ymax])\n",
    "\n",
    "# Plotting the test data\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(f\"Test: {len(test)} Classes: {len(test['Label'].unique())}\")\n",
    "ax = test['Label'].value_counts().plot(kind='bar')\n",
    "ax.set_ylim([ymin, ymax])\n",
    "\n",
    "# Saving and displaying the figure\n",
    "plt.savefig(LOGS_DIR + \"DatasetSplit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation\n",
    "\n",
    "In this cell, we'll use the imgaug library to create augmentation pipelines for the training,\n",
    "validation, and testing sets. The training set will be augmented more heavily than the validation\n",
    "and testing sets. We'll also create a data generator for each set, which will read the images\n",
    "from the dataframe, augment them, and normalize them on-the-fly while training.\n",
    "\n",
    "Further down, we'll set some model training parameters, such as the number of epochs, batch size,\n",
    "and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139035405
    }
   },
   "outputs": [],
   "source": [
    "# Setting the amount of dropout for our model (form of data augmentation)\n",
    "dropout_rate = 0.80\n",
    "\n",
    "# For the training set\n",
    "augs_for_train = iaa.Sequential([   \n",
    "                          iaa.Resize(224, interpolation = 'linear'),\n",
    "                          iaa.Fliplr(0.5),\n",
    "                          iaa.Flipud(0.5),\n",
    "                          iaa.Rot90([1, 2, 3, 4], True),\n",
    "                          iaa.Sometimes(.3, iaa.Affine(scale = (.95, 1.05))),\n",
    "                       ])\n",
    "\n",
    "# For the validation and testing sets\n",
    "augs_for_valid = iaa.Sequential([iaa.Resize(224, interpolation = 'linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139366467
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "# Batch size is dependent on the amount of memory available on your machine\n",
    "batch_size = 32\n",
    "\n",
    "# Defines the length of an epoch, all images are used\n",
    "steps_per_epoch_train = len(train)/batch_size\n",
    "steps_per_epoch_valid = len(valid)/batch_size\n",
    "\n",
    "# Learning rate \n",
    "lr = .0001\n",
    "\n",
    "# Training images are augmented, and then normalized\n",
    "train_augmentor = ImageDataGenerator(preprocessing_function = augs_for_train.augment_image)\n",
    "                                     \n",
    "                                                                   \n",
    "# Reading from dataframe\n",
    "train_generator = train_augmentor.flow_from_dataframe(dataframe = train, \n",
    "                                                      directory = None,\n",
    "                                                      x_col = 'Path',\n",
    "                                                      y_col = 'Label', \n",
    "                                                      target_size = (224, 224), \n",
    "                                                      color_mode = \"rgb\",  \n",
    "                                                      class_mode = 'categorical', \n",
    "                                                      batch_size = batch_size,\n",
    "                                                      shuffle = True,\n",
    "                                                      seed = 42)\n",
    "                                                     \n",
    "# Only normalize images, no augmentation\n",
    "validate_augmentor = ImageDataGenerator(preprocessing_function = augs_for_valid.augment_image)\n",
    "\n",
    "# Reading from dataframe                             \n",
    "validation_generator = validate_augmentor.flow_from_dataframe(dataframe = valid,\n",
    "                                                              directory = None, \n",
    "                                                              x_col = 'Path',\n",
    "                                                              y_col = 'Label', \n",
    "                                                              target_size = (224, 224), \n",
    "                                                              color_mode = \"rgb\",  \n",
    "                                                              class_mode = 'categorical', \n",
    "                                                              batch_size = batch_size, \n",
    "                                                              shuffle = True, \n",
    "                                                              seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation\n",
    "\n",
    "In this cell we'll create the model. We'll use the ConvNeXt architecture, which is a convolutional\n",
    "neural network that uses grouped convolutions to reduce the number of parameters. We'll use the\n",
    "pretrained weights from the ImageNet dataset, and we'll freeze the weights of the convolutional\n",
    "layers. We'll only train the fully-connected layers at the end of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139371355
    }
   },
   "outputs": [],
   "source": [
    "# Now we define the convolutional portion of the model\n",
    "convnet = keras.applications.convnext.ConvNeXtSmall(\n",
    "        model_name='convnext_small',\n",
    "        include_top=False,\n",
    "        include_preprocessing=True,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling='max',\n",
    "        classes=num_classes,\n",
    "        classifier_activation='softmax',\n",
    ")\n",
    "\n",
    "# Here we create the entire model, with the convnet previously defined\n",
    "# as the encoder. Our entire model is simple, consisting of the convnet,\n",
    "# a dropout layer for regularization, and a fully-connected layer with\n",
    "# softmax activation for classification.\n",
    "model = Sequential([\n",
    "        convnet,\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes),\n",
    "        Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the Model\n",
    "\n",
    "If you want, output the model summary to get an idea of the model architecture. This can be\n",
    "useful as the number of parameters in the model can be quite large, and that may affect the\n",
    "training time, and the amount of memory required to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139371718
    }
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Callbacks\n",
    "\n",
    "Here we define the callbacks that will be used during training. The first callback will reduce\n",
    "the learning rate by N% if the validation loss does not decrease after N epochs. The second callback\n",
    "will save the model weights after each epoch, but only if the validation loss decreases. The third\n",
    "callback will stop training if the validation loss does not decrease after N epochs. The fourth\n",
    "callback will write logs to a Tensorboard log file, which can be used to visualize the training\n",
    "progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372146
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=.65, patience=3, verbose=1),\n",
    "\n",
    "                ModelCheckpoint(filepath=WEIGHTS_DIR + 'model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5',\n",
    "                                 monitor='val_loss', save_weights_only=False, save_best_only=True, verbose=1),\n",
    "\n",
    "                EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, verbose=1,  mode=\"auto\",\n",
    "                              baseline=None, restore_best_weights=True),\n",
    "\n",
    "                TensorBoard(log_dir=LOGS_DIR, histogram_freq=1, write_graph=True, write_images=True, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the Model\n",
    "\n",
    "Here we define the model using the compile function. The compile function is not part of the\n",
    "model definition, but it is necessary to define the model before training. We use the Adam\n",
    "optimizer, and the categorical cross-entropy loss function. We also define the metrics that\n",
    "we want to track during training, in this case accuracy, precision, and recall.\n",
    "\n",
    "Any adjustments to the model training parameters will require you to recompile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372515
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=lr),\n",
    "              metrics=['acc', precision, recall, f1_score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Class Weights\n",
    "\n",
    "If you want to calculate the class weights for the training set, you can do so here. The class\n",
    "weights are used to weight the loss function during training. This is useful if the dataset is\n",
    "imbalanced, as it will help the model learn the minority classes better. If you do not want to\n",
    "use class weights, set the weighted variable to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372995
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the class weights, plot and save figure\n",
    "if True:\n",
    "    class_weight = compute_class_weights(train)\n",
    "else:\n",
    "    class_weight = {c: 1.0 for c in range(num_classes)}\n",
    "\n",
    "# Reformat for model.fit()\n",
    "class_weight = {i: list(class_weight.values())[i] for i in range(len(list(class_weight.values())))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Model\n",
    "\n",
    "In this cell we train the model. We use the fit function to train the model. We pass in the\n",
    "training and validation generators that we created earlier, as well as the number of epochs\n",
    "to train for. We also pass in the callbacks that we defined earlier, and the class weights\n",
    "that we calculated earlier. The fit function will return a history object that we can use\n",
    "to plot the training and validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678142616269
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch_train,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=steps_per_epoch_valid,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1,\n",
    "                    class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_history(history, single_graphs=True, path=f\"{LOGS_DIR}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting the Best Weights\n",
    "\n",
    "After training, we'll select the best weights to use for testing. We'll select the weights\n",
    "that yield the highest validation accuracy. We'll then load those weights into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678137877367
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of weights, sorted by modification time\n",
    "weights = sorted(glob.glob(WEIGHTS_DIR + \"*.h5\"), key=os.path.getmtime)\n",
    "[print(w, i) for i, w in enumerate(weights)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138613377
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the index with the best metrics\n",
    "best_weights = weights[-1]\n",
    "print(\"Best Weights: \", best_weights)\n",
    "\n",
    "# Load into the model\n",
    "model.load_weights(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Model\n",
    "\n",
    "Now we create a generator for the test set, and use the model to predict on the test set. We\n",
    "will print the classification report and plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138362359
    }
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each label\n",
    "label_counts = test['Label'].value_counts()\n",
    "\n",
    "# Sort the DataFrame based on label counts in descending order\n",
    "test_sorted = test.sort_values(by='Label', key=lambda x: x.map(label_counts), ascending=False)\n",
    "\n",
    "# Create the generator\n",
    "test_augmentor = ImageDataGenerator(preprocessing_function = augs_for_valid.augment_image)\n",
    "\n",
    "test_generator = test_augmentor.flow_from_dataframe(dataframe=test_sorted,\n",
    "                                                    x_col = 'Path',\n",
    "                                                    y_col = 'Label',\n",
    "                                                    target_size = (224, 224),\n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    shuffle = False,\n",
    "                                                    seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict on all the test set\n",
    "predictions = model.predict_generator(test_generator)\n",
    "\n",
    "# Collapse the probability distribution to the most likely category\n",
    "predict_classes = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create classification report\n",
    "report = classification_report(test_generator.classes,\n",
    "                               predict_classes,\n",
    "                               target_names=test_generator.class_indices.keys())\n",
    "\n",
    "# Save the report to a file\n",
    "with open(f\"{LOGS_DIR}Classification_Report.txt\", \"w\") as file:\n",
    "    file.write(report)\n",
    "\n",
    "# Display to user\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(test_generator.classes, predict_classes)\n",
    "# Calculate the number of samples\n",
    "num_samples = len(test_generator.classes)\n",
    "# Convert the accuracy and number of samples to strings\n",
    "accuracy_str = f\"{overall_accuracy:.2f}\"\n",
    "num_samples_str = str(num_samples)\n",
    "\n",
    "# Calculate the confusion matrix and normalize it\n",
    "cm = confusion_matrix(test_generator.classes, predict_classes)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_normalized = np.round(cm_normalized, decimals=2)\n",
    "\n",
    "# Get the sum of each row (number of samples per class)\n",
    "row_sums = cm.sum(axis=1)\n",
    "\n",
    "# Sort the confusion matrix and row sums in descending order\n",
    "sort_indices = np.argsort(row_sums)[::-1]\n",
    "cm_sorted = cm_normalized[sort_indices][:, sort_indices]\n",
    "class_labels_sorted = np.array(list(test_generator.class_indices.keys()))[sort_indices]\n",
    "\n",
    "# Create the display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_sorted, display_labels=class_labels_sorted)\n",
    "# Set the figure size\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax.set_title(f\"Confusion Matrix\\nOverall Accuracy: {accuracy_str}, Samples: {num_samples_str}\")\n",
    "# Plot the confusion matrix\n",
    "disp.plot(ax=ax, cmap=plt.cm.Blues, values_format='g')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.savefig(f\"{LOGS_DIR}Confusion_Matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the true labels to binary format\n",
    "binary_true_labels = label_binarize(test_generator.classes, classes=np.arange(num_classes))\n",
    "\n",
    "# Create a dict for the legend\n",
    "class_indices = {int(v): k for k, v in test_generator.class_indices.items()}\n",
    "\n",
    "# Compute the false positive rate (FPR), true positive rate (TPR), and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(binary_true_labels[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curves for each class\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(num_classes):\n",
    "    roc_val = np.around(roc_auc[i], 2)\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'{class_indices[i]} AUC = {roc_val}')\n",
    "\n",
    "# Plot the random guessing line\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')\n",
    "\n",
    "# Set plot properties\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc='lower right', title='Classes')\n",
    "plt.savefig(LOGS_DIR + \"ROC_Curves.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Threshold\n",
    "\n",
    "Here we define a confidence threshold. This is the minimum difference between the most\n",
    "probably class and the actual class. If the difference is less than this, the model is\n",
    "unsure of the prediction. We can use this to filter out the predictions that the model is\n",
    "unsure of, and only use the predictions that the model is sure of. This can be useful if\n",
    "we want to use the predictions from a model that is not very accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138505994
    }
   },
   "outputs": [],
   "source": [
    "# Higher values represent more sure/confident predictions\n",
    "# .1 unsure -> .5 pretty sure -> .9 very sure\n",
    "\n",
    "# Creating a graph of the threshold values and the accuracy\n",
    "threshold_values = np.arange(0.0, 1.0, 0.05)\n",
    "class_ACC = []\n",
    "sure_percentage = []\n",
    "\n",
    "# Looping through the threshold values and calculating the accuracy and percentage\n",
    "for threshold in threshold_values:\n",
    "    # Creating a list to store the sure index\n",
    "    sure_index = []\n",
    "    # Looping through all predictions and calculating the sure predictions\n",
    "    for i in range(0, len(predictions)):\n",
    "        # If the difference between the most probable class and the second most probable class\n",
    "        # is greater than the threshold, add it to the sure index\n",
    "        if (sorted(predictions[i])[-1]) - (sorted(predictions[i])[-2]) > threshold:\n",
    "            sure_index.append(i)\n",
    "\n",
    "    # Calculating the accuracy for the threshold value\n",
    "    sure_test_y = np.take(test_generator.classes, sure_index, axis=0)\n",
    "    sure_pred_y = np.take(predict_classes, sure_index)\n",
    "    sure_percentage.append(len(sure_index) / len(predictions))\n",
    "    class_ACC.append(accuracy_score(sure_test_y, sure_pred_y))\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(threshold_values, class_ACC)\n",
    "plt.plot(threshold_values, sure_percentage, color='gray', linestyle='--')\n",
    "plt.xlabel('Threshold Values')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([.5, 1])\n",
    "plt.xticks(ticks=np.arange(0, 1.05, 0.1))\n",
    "plt.ylabel('Classification Accuracy / Sure Percentage')\n",
    "plt.title('Identifying the ideal threshold value')\n",
    "plt.legend(['Classification Accuracy', 'Sure Percentage'])\n",
    "plt.savefig(LOGS_DIR + \"AccuracyThreshold.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Model\n",
    "\n",
    "Finally, we save the model and the weights. We save the model as a .h5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138507009
    }
   },
   "outputs": [],
   "source": [
    "model.save(f\"{MODEL_DIR}Best_Model_and_Weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "coralnet"
  },
  "kernelspec": {
   "name": "conda-env-.conda-coralnet_api-py",
   "language": "python",
   "display_name": "Python [conda env:.conda-coralnet_api] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "29187d11294c07bea965194f215d76d7c863eddc7d453727fd722f0612a38c27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
