{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223091038
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from imgaug import augmenters as iaa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223091206
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def compute_class_weights(df, mu=0.15):\n",
    "\n",
    "    value_counts = df['Label'].value_counts().to_dict()\n",
    "    total = sum(value_counts.values())\n",
    "    keys = value_counts.keys()\n",
    "\n",
    "    class_weight = dict()\n",
    "    \n",
    "    for key in keys:\n",
    "        \n",
    "        score = math.log(mu*total/float(value_counts[key]))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "    \n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223091360
    }
   },
   "outputs": [],
   "source": [
    "coarse_classes = {\n",
    "    'LC_Fol': 'Live_Coral', \n",
    "    'LC_Branch': 'Live_Coral', \n",
    "    'Ar_TA': 'Artificial', \n",
    "    'LC_Por': 'Live_Coral', \n",
    "    'UDC_CCA': 'Dead_Coral', \n",
    "    'Ro_TA': 'Rock', \n",
    "    'Pa_FA': 'Pavement', \n",
    "    'Mu_Ba': 'Mud', \n",
    "    'CR_TA': 'Coral_Rubble', \n",
    "    'Pa_Cy': 'Pavement', \n",
    "    'LC_Encr': 'Live_Coral', \n",
    "    'Sa_Ba': 'Sand', \n",
    "    'Pa_H': 'Pavement', \n",
    "    'Pa_TA': 'Pavement', \n",
    "    'UDC_H': 'Dead_Coral', \n",
    "    'CR_FA': 'Coral_Rubble', \n",
    "    'Ro_CCA': 'Rock', \n",
    "    'Mu_Cy': 'Mud', \n",
    "    'UDC_TA': 'Dead_Coral', \n",
    "    'Sa_Cy': 'Sand', \n",
    "    'UDC_FA': 'Dead_Coral', \n",
    "    'Ro_H': 'Rock', \n",
    "    'Sa_FA': 'Sand', \n",
    "    'Pa_CCA': 'Pavement', \n",
    "    'Ro_Ba': 'Rock', \n",
    "    'Ro_Cy': 'Rock', \n",
    "    'Sa_TA': 'Sand', \n",
    "    'Ar_Ba': 'Artificial', \n",
    "    'UDC_Cy': 'Dead_Coral', \n",
    "    'Ar_FA': 'Artificial', \n",
    "    'CR_CCA': 'Coral_Rubble'\n",
    "}\n",
    "\n",
    "functional_groups = {\n",
    "    'LC_Fol': 'Hard_Coral', \n",
    "    'LC_Branch': 'Hard_Coral', \n",
    "    'Ar_TA': 'Algae', \n",
    "    'LC_Por': 'Hard_Coral', \n",
    "    'UDC_CCA': 'Algae', \n",
    "    'Ro_TA': 'Algae', \n",
    "    'Pa_FA': 'Algae', \n",
    "    'Mu_Ba': 'Algae', \n",
    "    'CR_TA': 'Algae', \n",
    "    'Pa_Cy': 'Other', \n",
    "    'LC_Encr': 'Hard_Coral', \n",
    "    'Sa_Ba': 'Algae', \n",
    "    'Pa_H': 'Algae', \n",
    "    'Pa_TA': 'Algae', \n",
    "    'UDC_H': 'Algae', \n",
    "    'CR_FA': 'Algae', \n",
    "    'Ro_CCA': 'Algae', \n",
    "    'Mu_Cy': 'Other', \n",
    "    'UDC_TA': 'Algae', \n",
    "    'Sa_Cy': 'Other', \n",
    "    'UDC_FA': 'Algae', \n",
    "    'Ro_H': 'Algae', \n",
    "    'Sa_FA': 'Algae', \n",
    "    'Pa_CCA': 'Algae', \n",
    "    'Ro_Ba': 'Algae', \n",
    "    'Ro_Cy': 'Other', \n",
    "    'Sa_TA': 'Algae', \n",
    "    'Ar_Ba': 'Algae', \n",
    "    'UDC_Cy': 'Other', \n",
    "    'Ar_FA': 'Algae', \n",
    "    'CR_CCA': 'Algae'\n",
    "}\n",
    "\n",
    "short_codes = [\n",
    "    'LC_Fol', \n",
    "    'LC_Branch', \n",
    "    'Ar_TA', \n",
    "    'LC_Por', \n",
    "    'UDC_CCA', \n",
    "    'Ro_TA', \n",
    "    'Pa_FA', \n",
    "    'Mu_Ba', \n",
    "    'CR_TA', \n",
    "    'Pa_Cy', \n",
    "    'LC_Encr', \n",
    "    'Sa_Ba', \n",
    "    'Pa_H', \n",
    "    'Pa_TA', \n",
    "    'UDC_H', \n",
    "    'CR_FA', \n",
    "    'Ro_CCA', \n",
    "    'Mu_Cy', \n",
    "    'UDC_TA', \n",
    "    'Sa_Cy', \n",
    "    'UDC_FA', \n",
    "    'Ro_H', \n",
    "    'Sa_FA', \n",
    "    'Pa_CCA', \n",
    "    'Ro_Ba', \n",
    "    'Ro_Cy', \n",
    "    'Sa_TA', \n",
    "    'Ar_Ba', \n",
    "    'UDC_Cy', \n",
    "    'Ar_FA', \n",
    "    'CR_CCA'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223109037
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/azureuser/cloudfiles/code/Users/jordan.pierce/Data/Guam_Saipan/3653/\"\n",
    "assert os.path.exists(DATA_PATH)\n",
    "\n",
    "EXP_DIR = \"Experiments/\"\n",
    "EXP_NAME = \"Short_Codes_With_Weights_Even\"\n",
    "EXP_FOLDER = EXP_DIR + EXP_NAME + \"/\"\n",
    "WEIGHTS_DIR = EXP_FOLDER + \"Weights/\"\n",
    "LOGS_DIR = EXP_FOLDER + \"Logs/\"\n",
    "\n",
    "weighted = False if \"No_Weights\" in EXP_NAME else True\n",
    "\n",
    "os.makedirs(EXP_DIR, exist_ok=True)\n",
    "os.makedirs(EXP_FOLDER, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) \n",
    "os.makedirs(LOGS_DIR, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223112818
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH + \"Updated_CNet_Annotations.csv\", index_col=0)\n",
    "\n",
    "# List of Image Names\n",
    "image_names = data['Image'].unique().tolist()\n",
    "print(\"Number Images: \", len(image_names))\n",
    "\n",
    "if \"Coarse\" in EXP_NAME:\n",
    "    data[\"Label\"].replace(coarse_classes, inplace=True)\n",
    "elif \"Functional\" in EXP_NAME:\n",
    "    data[\"Label\"].replace(functional_groups, inplace=True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# All class categories in the dataset\n",
    "print(\"Class Categories: \", len(short_codes))\n",
    "\n",
    "# Getting a sample of each class category\n",
    "sample = pd.DataFrame()\n",
    "\n",
    "for category in short_codes:\n",
    "    c = data[data['Label'] == category].sample(n=1)\n",
    "    sample = pd.concat((sample, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223311802
    }
   },
   "outputs": [],
   "source": [
    "threshold_met = False\n",
    "seed = 0\n",
    "\n",
    "while not threshold_met:\n",
    "\n",
    "    # Split the Images into training, validation, and test sets.\n",
    "    training_images, testing_images = train_test_split(image_names, test_size=0.35, random_state=seed)\n",
    "    validation_images, testing_images = train_test_split(testing_images, test_size=0.5, random_state=seed)\n",
    "\n",
    "    train = data[data['Image'].isin(training_images)]\n",
    "    valid = data[data['Image'].isin(validation_images)]\n",
    "    test = data[data['Image'].isin(testing_images)]\n",
    "\n",
    "    train = pd.concat((train, sample))\n",
    "    valid = pd.concat((valid, sample))\n",
    "    test = pd.concat((test, sample))\n",
    "\n",
    "    # Concatenate the three dataframes\n",
    "    combined_df = pd.concat([train, valid, test])\n",
    "\n",
    "    # Calculate class percentages for the combined dataframe\n",
    "    grouped_df = combined_df.groupby(\"Label\")\n",
    "    class_counts = grouped_df.size()\n",
    "    class_percentages_combined = class_counts / len(combined_df) * 100\n",
    "\n",
    "    # Calculate class percentages for each of the three dataframes\n",
    "    grouped_train = train.groupby(\"Label\")\n",
    "    class_counts_train = grouped_train.size()\n",
    "    class_percentages_train = class_counts_train / len(train) * 100\n",
    "\n",
    "    grouped_valid = valid.groupby(\"Label\")\n",
    "    class_counts_valid = grouped_valid.size()\n",
    "    class_percentages_valid = class_counts_valid / len(valid) * 100\n",
    "\n",
    "    grouped_test = test.groupby(\"Label\")\n",
    "    class_counts_test = grouped_test.size()\n",
    "    class_percentages_test = class_counts_test / len(test) * 100\n",
    "\n",
    "    # Calculate mean squared error between class percentages for each pair of dataframes\n",
    "    mse_train_valid = mean_squared_error(class_percentages_train, class_percentages_valid)\n",
    "    mse_train_test = mean_squared_error(class_percentages_train, class_percentages_test)\n",
    "    mse_valid_test = mean_squared_error(class_percentages_valid, class_percentages_test)\n",
    "\n",
    "    # Set the threshold to be the average of the MSE values\n",
    "    threshold = 1.05 * (mse_train_valid + mse_train_test + mse_valid_test) / 3\n",
    "\n",
    "    # Determine if the class distributions are close enough for your use case\n",
    "    if mse_train_valid <= threshold and mse_train_test <= threshold and mse_valid_test <= threshold:\n",
    "\n",
    "        threshold_met = True\n",
    "        print(\"Class distributions are similar between all three dataframes.\")\n",
    "\n",
    "        # Print the MSE values\n",
    "        print(\"MSE between train and valid: {:.4f}\".format(mse_train_valid))\n",
    "        print(\"MSE between train and test: {:.4f}\".format(mse_train_test))\n",
    "        print(\"MSE between valid and test: {:.4f}\".format(mse_valid_test))\n",
    "\n",
    "    else:\n",
    "        seed += 1\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Train: \" + str(len(train)))\n",
    "ax = train['Label'].value_counts().plot(kind='bar')\n",
    "ax.set_xticklabels(short_codes)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Valid: \" + str(len(valid)))\n",
    "ax = valid['Label'].value_counts().plot(kind='bar')\n",
    "ax.set_xticklabels(short_codes)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Test: \" + str(len(test)))\n",
    "ax = test['Label'].value_counts().plot(kind='bar')\n",
    "ax.set_xticklabels(short_codes)\n",
    "plt.savefig(EXP_FOLDER + \"DatasetSplit.png\")\n",
    "plt.show()\n",
    "\n",
    "# List of Class Categories\n",
    "print(\"Train Class Categories: \", len(short_codes))\n",
    "print(\"Validation Class Categories: \", len(valid['Label'].unique().tolist()))\n",
    "print(\"Test Class Categories: \", len(test['Label'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139035405
    }
   },
   "outputs": [],
   "source": [
    "# Augmentation methods implemented using imgaug; training augmentations should be \n",
    "# more intense, whereas the validation and testing augmentations should be minimal to none.\n",
    "\n",
    "# Setting the amount of dropout for our model (form of data augmentation)\n",
    "dropout_rate = 0.80\n",
    "\n",
    "augs_for_train = iaa.Sequential([   \n",
    "                          iaa.Resize(224, interpolation = 'linear'),\n",
    "                          iaa.Fliplr(0.5),\n",
    "                          iaa.Flipud(0.5),\n",
    "                          iaa.Rot90([1, 2, 3, 4], True),\n",
    "                          iaa.Sometimes(.3, iaa.Affine(scale = (.95, 1.05))),\n",
    "                          iaa.Sometimes(.1, iaa.Invert(1.0)),\n",
    "                          iaa.Sometimes(.5, iaa.SomeOf((0, 1), \n",
    "                                             [\n",
    "                                                 iaa.MedianBlur(3),\n",
    "                                                 iaa.ChannelShuffle(.7),\n",
    "                                                 iaa.EdgeDetect(.5)\n",
    "                                             ])),\n",
    "\n",
    "                          iaa.Sometimes(.5, iaa.SomeOf((0, 1),\n",
    "                                            [\n",
    "                                                 iaa.Dropout(.2),\n",
    "                                                 iaa.ImpulseNoise(.2),\n",
    "                                                 iaa.SaltAndPepper(.2)\n",
    "                                            ]))\n",
    "                       ])\n",
    "\n",
    "\n",
    "augs_for_valid = iaa.Sequential([iaa.Resize(224, interpolation = 'linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139366467
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data generators are made to take the patch file paths currently stored in the dataframes; generators\n",
    "# create an augmentation pipeline so that patches can be read, augmented, and normalized on-the-fly \n",
    "# while training.\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Batch size is dependent on the amount of memory available on your machine\n",
    "batch_size = 32\n",
    "\n",
    "# Defines the length of an epoch, all images are used\n",
    "steps_per_epoch_train = len(train)/batch_size\n",
    "steps_per_epoch_valid = len(valid)/batch_size\n",
    "\n",
    "# Learning rate \n",
    "lr = .0001\n",
    "\n",
    "# Training images are augmented, and then normalized\n",
    "train_augmentor = ImageDataGenerator(preprocessing_function = augs_for_train.augment_image)\n",
    "                                     \n",
    "                                                                   \n",
    "# Reading from dataframe\n",
    "train_generator = train_augmentor.flow_from_dataframe(dataframe = train, \n",
    "                                                      directory = None,\n",
    "                                                      x_col = 'Patch_Name', \n",
    "                                                      y_col = 'Label', \n",
    "                                                      target_size = (224, 224), \n",
    "                                                      color_mode = \"rgb\",  \n",
    "                                                      class_mode = 'categorical', \n",
    "                                                      batch_size = batch_size,\n",
    "                                                      shuffle = True, \n",
    "                                                      seed = 42)\n",
    "                                                     \n",
    "# Only normalize images, no augmentation\n",
    "validate_augmentor = ImageDataGenerator( preprocessing_function = augs_for_valid.augment_image)\n",
    "\n",
    "# Reading from dataframe                             \n",
    "validation_generator = validate_augmentor.flow_from_dataframe(dataframe = valid,\n",
    "                                                              directory = None, \n",
    "                                                              x_col = 'Patch_Name', \n",
    "                                                              y_col = 'Label', \n",
    "                                                              target_size = (224, 224), \n",
    "                                                              color_mode = \"rgb\",  \n",
    "                                                              class_mode = 'categorical', \n",
    "                                                              batch_size = batch_size, \n",
    "                                                              shuffle = True, \n",
    "                                                              seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139371355
    }
   },
   "outputs": [],
   "source": [
    "# Now we create the model!\n",
    "\n",
    "convnet = tensorflow.keras.applications.convnext.ConvNeXtTiny(\n",
    "        model_name='convnext_tiny',\n",
    "        include_top=False,\n",
    "        include_preprocessing=True,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling='max',\n",
    "        classes=len(short_codes),\n",
    "        classifier_activation='softmax',\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "        convnet,\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(short_codes)),\n",
    "        Activation('softmax')\n",
    "])\n",
    "\n",
    "# Display the model architecture\n",
    "if True:\n",
    "    model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139371718
    }
   },
   "outputs": [],
   "source": [
    "# Defining the Recall and Precision metric functions\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372146
    }
   },
   "outputs": [],
   "source": [
    "# Defining training callbacks, such as learning rate, which will reduce after two epochs by %65 if the validation loss \n",
    "# does not decrease. Only the epochs with lower validation loss values will be saved.\n",
    "\n",
    "callbacks = [\n",
    "                ReduceLROnPlateau(monitor = 'val_loss', factor = .65, patience = 5, verbose = 1),\n",
    "                 \n",
    "                ModelCheckpoint(filepath = WEIGHTS_DIR + 'model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', \n",
    "                                 monitor='val_loss', save_weights_only = True, save_best_only = False, verbose = 1),\n",
    "\n",
    "                EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, verbose=0,  mode=\"auto\", baseline=None,\n",
    "                             restore_best_weights=True, start_from_epoch=0)\n",
    "\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372515
    }
   },
   "outputs": [],
   "source": [
    "# sets the loss function, optimizier and metrics, probably don't need to change\n",
    "# except maybe the learing rate \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizers.Adam(learning_rate=0.00001), \n",
    "              metrics=['acc', precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372995
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the class weights, plot and save figure\n",
    "if weighted:\n",
    "    class_weight = compute_class_weights(train)\n",
    "else:\n",
    "    class_weight = {c: 1.0 for c in short_codes}\n",
    "\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.bar(class_weight.keys(), class_weight.values())\n",
    "plt.title(\"ClassWeight\")\n",
    "plt.savefig(EXP_FOLDER + \"ClassWeight.png\")\n",
    "plt.show()\n",
    "\n",
    "# Reformat for model.fit()\n",
    "class_weight = {short_codes.index(k): v for (k, v) in class_weight.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678142616269
    }
   },
   "outputs": [],
   "source": [
    "# Train the model, logs the results of the training in history\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    steps_per_epoch = steps_per_epoch_train, \n",
    "                    epochs = num_epochs, \n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = steps_per_epoch_valid,\n",
    "                    callbacks = callbacks,\n",
    "                    verbose = 1,\n",
    "                    class_weight = class_weight)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678137877367
    }
   },
   "outputs": [],
   "source": [
    "# After training, loads the best weights\n",
    "weights = sorted(glob.glob(WEIGHTS_DIR + \"*.h5\"), key=os.path.getmtime)\n",
    "[print(w, i) for i, w in enumerate(weights)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138613377
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_weights = weights[3]\n",
    "print(\"Best Weights: \", best_weights)\n",
    "model.load_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138362359
    }
   },
   "outputs": [],
   "source": [
    "# Reads from dataframe for test set\n",
    "test_generator = validate_augmentor.flow_from_dataframe(dataframe=test, \n",
    "                                                        x_col = 'Patch_Name', \n",
    "                                                        y_col = 'Label', \n",
    "                                                        target_size = (224, 224), \n",
    "                                                        color_mode = \"rgb\",  \n",
    "                                                        class_mode = 'categorical', \n",
    "                                                        batch_size = batch_size, \n",
    "                                                        shuffle = False, \n",
    "                                                        seed = 42)\n",
    "# Grab the ground-truth\n",
    "test_y = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the length of an epoch\n",
    "steps_per_epoch_test = len(test)//1\n",
    "\n",
    "# Use the model to predict on all of the test set\n",
    "predictions = model.predict_generator(test_generator, steps=steps_per_epoch_test)\n",
    "\n",
    "# Collapse the probability distribution to the most likely category\n",
    "predict_classes = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_y), len(predict_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138743554
    }
   },
   "outputs": [],
   "source": [
    "print(\"# of images:\", len(predict_classes))\n",
    "\n",
    "# Create the confusion matrix between the ground-truth and predicted\n",
    "cm = confusion_matrix(y_true=test_y, y_pred=predict_classes)\n",
    "\n",
    "# Create a display for the confusion matrix, providing the labels\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=short_codes)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true=test_y,\n",
    "                                  y_pred=predict_classes)\n",
    "\n",
    "# Calculate the accuracy per class category, store in a dict\n",
    "class_accuracy = cm.diagonal()/cm.sum(axis=1)\n",
    "class_accuracy = dict(zip(short_codes, class_accuracy))\n",
    "\n",
    "# Write the accuracy per class category to a .csv file\n",
    "df = pd.DataFrame(list(zip(class_accuracy.keys(), class_accuracy.values())),\n",
    "                  columns=['Class', 'Accuracy'])\n",
    "\n",
    "df.to_csv(EXP_FOLDER + \"ClassAccuracy.csv\")\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "plt.title(\"Overall Accuracy :\" + str(overall_accuracy))\n",
    "disp.plot(ax=ax)\n",
    "plt.savefig(EXP_FOLDER + \"ConfusionMatrix.png\")\n",
    "print(\"Class Accuracy: \", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138505994
    }
   },
   "outputs": [],
   "source": [
    "# Higher values represents more sure/confident predictions\n",
    "# .1 unsure -> .5 pretty sure -> .9 very sure\n",
    "\n",
    "# Creating a graph of the threshold values and the accuracy\n",
    "# useful for determing how sure the model is when making predictions\n",
    "\n",
    "threshold_values = np.arange(0.0, 1.0, 0.05)\n",
    "class_ACC = []\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    sure_index = []\n",
    "\n",
    "    for i in range(0, len(predictions)):\n",
    "        if( (sorted(predictions[i])[-1]) - (sorted(predictions[i])[-2]) > threshold):\n",
    "            sure_index.append(i)\n",
    "\n",
    "    sure_test_y = np.take(test_y, sure_index, axis = 0)\n",
    "    sure_pred_y = np.take(predict_classes, sure_index)\n",
    "\n",
    "    class_ACC.append(accuracy_score(sure_test_y, sure_pred_y)) \n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(threshold_values, class_ACC)\n",
    "plt.xlabel('Threshold Values')\n",
    "plt.xlim([0, 1])\n",
    "plt.xticks(ticks = np.arange(0, 1.05, 0.1))\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.title('Identifying the ideal threshold value')\n",
    "plt.savefig(EXP_FOLDER + \"AccuracyThreshold.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138507009
    }
   },
   "outputs": [],
   "source": [
    "model.save(WEIGHTS_DIR + \"Best_Model_and_Weights.h5\")\n",
    "model.layers[0].save_weights(WEIGHTS_DIR + 'pre_trained_convnet_weights_3361.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "coralnet"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "29187d11294c07bea965194f215d76d7c863eddc7d453727fd722f0612a38c27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
