{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Train Image Classifier (Notebook)\n",
    "\n",
    "This notebook can be used to train a patch-based image classifier on the data downloaded from\n",
    "CoralNet. The data (images and annotations) must have been downloaded, and using the Annotations\n",
    " to Patches Notebook / script, made patches."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers, losses, metrics\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from imgaug import augmenters as iaa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setting Data Paths\n",
    "\n",
    "Here we'll set the path to the directory containing the data for the source we want to use.\n",
    "In this case, we're using the data downloaded from source 3420."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223109037
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Root and Source directory\n",
    "ROOT = \"../CoralNet_Data/\"\n",
    "SOURCE_DIR = ROOT + \"3420/\"\n",
    "\n",
    "# Patch dataframe\n",
    "patches_df = pd.read_csv(SOURCE_DIR + \"patches.csv\")\n",
    "\n",
    "# We'll also create folders in this source to hold results of the model\n",
    "MODEL_DIR = SOURCE_DIR + \"model/\"\n",
    "WEIGHTS_DIR = MODEL_DIR + \"weights/\"\n",
    "LOGS_DIR = MODEL_DIR + \"logs/\"\n",
    "\n",
    "# Make the directories\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) \n",
    "os.makedirs(LOGS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prepare Data\n",
    "\n",
    "Here we'll prepare the data for training. We'll use the annotations to create a dataframe\n",
    "containing the image names and their labels. We'll then split the data into training, validation,\n",
    "and testing sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_names = patches_df['Image_Name'].unique()\n",
    "\n",
    "# Split the Images into training, validation, and test sets.\n",
    "# We split based on the image names, so that we don't have the same image in multiple sets.\n",
    "training_images, testing_images = train_test_split(image_names, test_size=0.35, random_state=42)\n",
    "validation_images, testing_images = train_test_split(testing_images, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create training, validation, and test dataframes\n",
    "train = patches_df[patches_df['Image_Name'].isin(training_images)]\n",
    "valid = patches_df[patches_df['Image_Name'].isin(validation_images)]\n",
    "test = patches_df[patches_df['Image_Name'].isin(testing_images)]\n",
    "\n",
    "# The number of class categories\n",
    "num_classes = len(patches_df['Label'].unique())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Exploration\n",
    "\n",
    "As a sanity check, we can see how many images are in each set, and the class distribution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678223311802
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Train: \" + str(len(train)))\n",
    "ax = train['Label'].value_counts().plot(kind='bar')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Valid: \" + str(len(valid)))\n",
    "ax = valid['Label'].value_counts().plot(kind='bar')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Test: \" + str(len(test)))\n",
    "ax = test['Label'].value_counts().plot(kind='bar')\n",
    "plt.savefig(LOGS_DIR + \"DatasetSplit.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Augmentation\n",
    "\n",
    "In this cell, we'll use the imgaug library to create augmentation pipelines for the training,\n",
    "validation, and testing sets. The training set will be augmented more heavily than the validation\n",
    "and testing sets. We'll also create a data generator for each set, which will read the images\n",
    "from the dataframe, augment them, and normalize them on-the-fly while training.\n",
    "\n",
    "Further down, we'll set some model training parameters, such as the number of epochs, batch size,\n",
    "and learning rate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139035405
    }
   },
   "outputs": [],
   "source": [
    "# Setting the amount of dropout for our model (form of data augmentation)\n",
    "dropout_rate = 0.80\n",
    "\n",
    "# For the training set\n",
    "augs_for_train = iaa.Sequential([   \n",
    "                          iaa.Resize(224, interpolation = 'linear'),\n",
    "                          iaa.Fliplr(0.5),\n",
    "                          iaa.Flipud(0.5),\n",
    "                          iaa.Rot90([1, 2, 3, 4], True),\n",
    "                          iaa.Sometimes(.3, iaa.Affine(scale = (.95, 1.05))),\n",
    "                       ])\n",
    "\n",
    "# For the validation and testing sets\n",
    "augs_for_valid = iaa.Sequential([iaa.Resize(224, interpolation = 'linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139366467
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Batch size is dependent on the amount of memory available on your machine\n",
    "batch_size = 32\n",
    "\n",
    "# Defines the length of an epoch, all images are used\n",
    "steps_per_epoch_train = len(train)/batch_size\n",
    "steps_per_epoch_valid = len(valid)/batch_size\n",
    "\n",
    "# Learning rate \n",
    "lr = .0001\n",
    "\n",
    "# Training images are augmented, and then normalized\n",
    "train_augmentor = ImageDataGenerator(preprocessing_function = augs_for_train.augment_image)\n",
    "                                     \n",
    "                                                                   \n",
    "# Reading from dataframe\n",
    "train_generator = train_augmentor.flow_from_dataframe(dataframe = train, \n",
    "                                                      directory = None,\n",
    "                                                      x_col = 'Name',\n",
    "                                                      y_col = 'Label', \n",
    "                                                      target_size = (224, 224), \n",
    "                                                      color_mode = \"rgb\",  \n",
    "                                                      class_mode = 'categorical', \n",
    "                                                      batch_size = batch_size,\n",
    "                                                      shuffle = True, \n",
    "                                                      seed = 42)\n",
    "                                                     \n",
    "# Only normalize images, no augmentation\n",
    "validate_augmentor = ImageDataGenerator( preprocessing_function = augs_for_valid.augment_image)\n",
    "\n",
    "# Reading from dataframe                             \n",
    "validation_generator = validate_augmentor.flow_from_dataframe(dataframe = valid,\n",
    "                                                              directory = None, \n",
    "                                                              x_col = 'Name',\n",
    "                                                              y_col = 'Label', \n",
    "                                                              target_size = (224, 224), \n",
    "                                                              color_mode = \"rgb\",  \n",
    "                                                              class_mode = 'categorical', \n",
    "                                                              batch_size = batch_size, \n",
    "                                                              shuffle = True, \n",
    "                                                              seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Creation\n",
    "\n",
    "In this cell we'll create the model. We'll use the ConvNeXt architecture, which is a convolutional\n",
    "neural network that uses grouped convolutions to reduce the number of parameters. We'll use the\n",
    "pretrained weights from the ImageNet dataset, and we'll freeze the weights of the convolutional\n",
    "layers. We'll only train the fully-connected layers at the end of the network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139371355
    }
   },
   "outputs": [],
   "source": [
    "# Now we define the convolutional portion of the model\n",
    "convnet = tensorflow.keras.applications.convnext.ConvNeXtTiny(\n",
    "        model_name='convnext_tiny',\n",
    "        include_top=False,\n",
    "        include_preprocessing=True,\n",
    "        weights='imagenet',\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling='max',\n",
    "        classes=num_classes,\n",
    "        classifier_activation='softmax',\n",
    ")\n",
    "\n",
    "# Here we create the entire model, with the convnet previously defined\n",
    "# as the encoder. Our entire model is simple, consisting of the convnet,\n",
    "# a dropout layer for regularization, and a fully-connected layer with\n",
    "# softmax activation for classification.\n",
    "model = Sequential([\n",
    "        convnet,\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(num_classes),\n",
    "        Activation('softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualizing the Model\n",
    "\n",
    "If you want, output the model summary to get an idea of the model architecture. This can be\n",
    "useful as the number of parameters in the model can be quite large, and that may affect the\n",
    "training time, and the amount of memory required to train the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139371718
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Defining Callbacks\n",
    "\n",
    "Here we define the callbacks that will be used during training. The first callback will reduce\n",
    "the learning rate by N% if the validation loss does not decrease after N epochs. The second callback\n",
    "will save the model weights after each epoch, but only if the validation loss decreases. The third\n",
    "callback will stop training if the validation loss does not decrease after N epochs. The fourth\n",
    "callback will write logs to a Tensorboard log file, which can be used to visualize the training\n",
    "progress."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372146
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "                ReduceLROnPlateau(monitor='val_loss', factor=.65, patience=5, verbose=1),\n",
    "\n",
    "                ModelCheckpoint(filepath=WEIGHTS_DIR + 'model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5',\n",
    "                                 monitor='val_loss', save_weights_only=True, save_best_only=False, verbose=1),\n",
    "\n",
    "                EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, verbose=0,  mode=\"auto\", baseline=None,\n",
    "                             restore_best_weights=True, start_from_epoch=0),\n",
    "\n",
    "                Tensorboard(log_dir=LOGS_DIR, histogram_freq=0, write_graph=True, write_images=True, update_freq='epoch',\n",
    "                            profile_batch=2, embeddings_freq=0, embeddings_metadata=None),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Compiling the Model\n",
    "\n",
    "Here we define the model using the compile function. The compile function is not part of the\n",
    "model definition, but it is necessary to define the model before training. We use the Adam\n",
    "optimizer, and the categorical cross-entropy loss function. We also define the metrics that\n",
    "we want to track during training, in this case accuracy, precision, and recall.\n",
    "\n",
    "Any adjustments to the model training parameters will require you to recompile the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372515
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=lr),\n",
    "              metrics=['acc', precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Calculating Class Weights\n",
    "\n",
    "If you want to calculate the class weights for the training set, you can do so here. The class\n",
    "weights are used to weight the loss function during training. This is useful if the dataset is\n",
    "imbalanced, as it will help the model learn the minority classes better. If you do not want to\n",
    "use class weights, set the weighted variable to False."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678139372995
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the class weights, plot and save figure\n",
    "if True:\n",
    "    class_weight = compute_class_weights(train)\n",
    "else:\n",
    "    class_weight = {c: 1.0 for c in range(len(num_classes))}\n",
    "\n",
    "# Reformat for model.fit()\n",
    "class_weight = {short_codes.index(k): v for (k, v) in class_weight.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training the Model\n",
    "\n",
    "In this cell we train the model. We use the fit function to train the model. We pass in the\n",
    "training and validation generators that we created earlier, as well as the number of epochs\n",
    "to train for. We also pass in the callbacks that we defined earlier, and the class weights\n",
    "that we calculated earlier. The fit function will return a history object that we can use\n",
    "to plot the training and validation loss and accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678142616269
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=steps_per_epoch_train,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=steps_per_epoch_valid,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1,\n",
    "                    class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Selecting the Best Weights\n",
    "\n",
    "After training, we'll select the best weights to use for testing. We'll select the weights\n",
    "that yield the highest validation accuracy. We'll then load those weights into the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678137877367
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of weights, sorted by modification time\n",
    "weights = sorted(glob.glob(WEIGHTS_DIR + \"*.h5\"), key=os.path.getmtime)\n",
    "[print(w, i) for i, w in enumerate(weights)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138613377
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the index with the best metrics\n",
    "best_weights = weights[3]\n",
    "print(\"Best Weights: \", best_weights)\n",
    "\n",
    "# Load into the model\n",
    "model.load_weights(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing the Model\n",
    "\n",
    "Now we create a generator for the test set, and use the model to predict on the test set. We\n",
    "will print the classification report and plot the confusion matrix."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138362359
    }
   },
   "outputs": [],
   "source": [
    "test_generator = validate_augmentor.flow_from_dataframe(dataframe=test,\n",
    "                                                        x_col = 'Name',\n",
    "                                                        y_col = 'Label', \n",
    "                                                        target_size = (224, 224), \n",
    "                                                        color_mode = \"rgb\",  \n",
    "                                                        class_mode = 'categorical', \n",
    "                                                        batch_size = batch_size, \n",
    "                                                        shuffle = False, \n",
    "                                                        seed = 42)\n",
    "# Grab the ground-truth\n",
    "test_y = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the length of an epoch\n",
    "steps_per_epoch_test = len(test)//1\n",
    "\n",
    "# Use the model to predict on all of the test set\n",
    "predictions = model.predict_generator(test_generator, steps=steps_per_epoch_test)\n",
    "\n",
    "# Collapse the probability distribution to the most likely category\n",
    "predict_classes = np.argmax(predictions, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138743554
    }
   },
   "outputs": [],
   "source": [
    "print(\"# of images:\", len(predict_classes))\n",
    "\n",
    "# Create the confusion matrix between the ground-truth and predicted\n",
    "cm = confusion_matrix(y_true=test_y, y_pred=predict_classes)\n",
    "\n",
    "# Create a display for the confusion matrix, providing the labels\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=short_codes)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_true=test_y,\n",
    "                                  y_pred=predict_classes)\n",
    "\n",
    "# Calculate the accuracy per class category, store in a dict\n",
    "class_accuracy = cm.diagonal()/cm.sum(axis=1)\n",
    "class_accuracy = dict(zip(short_codes, class_accuracy))\n",
    "\n",
    "# Write the accuracy per class category to a .csv file\n",
    "df = pd.DataFrame(list(zip(class_accuracy.keys(),\n",
    "                           class_accuracy.values())),\n",
    "                  columns=['Class', 'Accuracy'])\n",
    "\n",
    "df.to_csv(LOGS_DIR + \"ClassAccuracy.csv\")\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "plt.title(\"Overall Accuracy :\" + str(overall_accuracy))\n",
    "disp.plot(ax=ax)\n",
    "plt.savefig(LOGS_DIR + \"ConfusionMatrix.png\")\n",
    "print(\"Class Accuracy: \", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Confidence Threshold\n",
    "\n",
    "Here we define a confidence threshold. This is the minimum difference between the most\n",
    "probably class and the actual class. If the difference is less than this, the model is\n",
    "unsure of the prediction. We can use this to filter out the predictions that the model is\n",
    "unsure of, and only use the predictions that the model is sure of. This can be useful if\n",
    "we want to use the predictions from a model that is not very accurate."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138505994
    }
   },
   "outputs": [],
   "source": [
    "# Higher values represents more sure/confident predictions\n",
    "# .1 unsure -> .5 pretty sure -> .9 very sure\n",
    "\n",
    "# Creating a graph of the threshold values and the accuracy\n",
    "# useful for determining how sure the model is when making predictions\n",
    "threshold_values = np.arange(0.0, 1.0, 0.05)\n",
    "class_ACC = []\n",
    "\n",
    "# Looping through the threshold values and calculating the accuracy\n",
    "for threshold in threshold_values:\n",
    "    # Creating a list to store the sure index\n",
    "    sure_index = []\n",
    "    #  Looping through all predictions and calculating the sure predictions\n",
    "    for i in range(0, len(predictions)):\n",
    "        # If the difference between the most probable class and the actual class\n",
    "        # is greater than the threshold, add it to the sure index\n",
    "        if(sorted(predictions[i])[-1]) - (sorted(predictions[i])[-2]) > threshold:\n",
    "            sure_index.append(i)\n",
    "\n",
    "    #  Calculating the accuracy for the threshold value\n",
    "    sure_test_y = np.take(test_y, sure_index, axis = 0)\n",
    "    sure_pred_y = np.take(predict_classes, sure_index)\n",
    "\n",
    "    class_ACC.append(accuracy_score(sure_test_y, sure_pred_y)) \n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(threshold_values, class_ACC)\n",
    "plt.xlabel('Threshold Values')\n",
    "plt.xlim([0, 1])\n",
    "plt.xticks(ticks = np.arange(0, 1.05, 0.1))\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.title('Identifying the ideal threshold value')\n",
    "plt.savefig(LOGS_DIR + \"AccuracyThreshold.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Saving the Model\n",
    "\n",
    "Finally, we save the model and the weights. We save the model as a .h5 file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1678138507009
    }
   },
   "outputs": [],
   "source": [
    "model.save(WEIGHTS_DIR + \"Best_Model_and_Weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "coralnet"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "29187d11294c07bea965194f215d76d7c863eddc7d453727fd722f0612a38c27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
