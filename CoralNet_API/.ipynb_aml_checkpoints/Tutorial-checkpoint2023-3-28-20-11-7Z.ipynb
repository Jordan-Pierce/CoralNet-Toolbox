{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CoralNet API\n",
        "\n",
        "This notebook is meant to guide you through the process of using the CoralNet API so that you can obtain sparse labels for an image using an already trained classifier (i.e. source). The general process is shown in the figure below, where we first submit a request to CoralNet using their API instructing which source we want to use, the image(s) we're trying to annotate, and the location we want the sparse labels to be (that's right, we get to specify). After submitting the request, we wait and periodically check back to see the progress. Once the request has been completed, we're sent back the annotations, which are then converted into a .csv file.\n",
        "\n",
        "![alt text](Figures/Workflow.png \"Workflow\")\n",
        "\n",
        "This code is merely meant to serve as a guide; it may not work exactly how you want it to, but hopefully, it can get you started. It should also be known that this code is based on the code written by Scott Miller (thanks Scott!)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Dropbox\n",
        "\n",
        "First we'll set up the Dropbox account (assuming you don't already have one made), and then we'll walkthrough the steps of creating an application so that we can give the CoralNet source the ability to access our images.\n",
        "\n",
        "So, go to [www.dropbox.com](www.dropbox.com) and create a free account (jot down the username and password so you don't forget). By default you're allocated 2GB for memory, but you can expand upon that for a price. After creating and finalizing the account, go ahead and create a **base folder** named `CoralNet` and in this folder, you're going to create a seperate folder for each project you're working on, which we'll refer to as **project folders**. \n",
        "\n",
        "For example, I'm working on some Autonmous Reef Monitoring Survey (ARMS) images that were collected in Hong Kong as a part of the the MarineGEO project (see below).\n",
        "\n",
        "In the project folder, place all of the images you want annotated (see my `ARMS` project folder as an example)\n",
        "\n",
        "![alt text](Figures/Dropbox_project.png \"Dropbox\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an Application\n",
        "\n",
        "Now that we have our images in the **project folder**, we're going to give CoralNet permission to access them by creating an application (wow so _fancy_). To do this you're going to go to [https://www.dropbox.com/developers/apps](https://www.dropbox.com/developers/apps) and create an application like so:\n",
        "\n",
        "![alt text](Figures/Application.png \"Application\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "From here you're going to do two things: change the authorization to allow CoralNet to gain access and some minor prilivages (e.g., read files), and obtain a token that you'll use as a form of identification when submitting the requests to CoralNet. \n",
        "\n",
        "To set the authorization, scroll down to `Permission type` and click on the `Scoped App` hyperlink. \n",
        "\n",
        "![alt text](Figures/Token_1.png \"Token 1\")\n",
        "\n",
        "On this page you'll want to change the setting to the following things:\n",
        "\n",
        "![alt text](Figures/Token_2.png \"Token 2\")\n",
        "\n",
        "Note CoralNet needs some permissions, but don't give more permission than what you feel comfortable with."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "After submitting those changes, return to the previous page and scroll down untill you see `OAuth 2`; here you can do one of two things: you can either use a `Short-lived` token, which means that the token generated will only last about 24hrs, and it will then become unusable (and therefore you'll need to generate a new one). \n",
        "\n",
        "Alternatively, you can generate a token that has `No expiration`, which is convenient, but could leave your data vulnerable if that token accidently makes it's way into the wrong hands (damn you criminals, always trying to steal our pictures of corals).\n",
        "\n",
        "Conceptually you can think of the token as a sort of key into you account, and based on the permissions that you provide the app, more or less can be done once gaining access. Your call.\n",
        "\n",
        "After you've finished deliberating, press `Generate` to generate a token. Copy and save this for later.\n",
        "\n",
        "![alt text](Figures/Token_3.png \"Token 3\")"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Code  \n",
        "Now that `dropbox` is setup we can move on to actually making requests using the code below. Note that this tutorial makes the assumption that you're comfortable setting up a virtual environment using `Anaconda` (or some similiar variant), and can install libraries using a environment/package manager such as `conda` or `pip`. If not, maybe check out this YouTube video first:\n",
        "\n",
        "[![Anaconda](Figures/anaconda_python.png)](https://www.youtube.com/watch?v=YJC6ldI3hWk)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can start with installing the libraries needed to run the code:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import random\n",
        "\n",
        "import json\n",
        "import dropbox\n",
        "import requests\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from utils import *"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dropbox'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdropbox\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dropbox'"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1682712643557
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of these, the only one that you probably don't already have installed is `dropbox`, which can be installed with `conda` or `pip` by writing the following in your terminal:\n",
        "\n",
        "`pip install dropbox`\n",
        "\n",
        "or\n",
        "\n",
        "`conda install dropbox`\n",
        "\n",
        "if you don't already have the other libraries, they can be installed in a similar manner. If you have problems, Google will solve them for you.\n",
        "\n",
        "Last is a custom library of utilies made by yours truly to assist in getting annotations and checking the status of the `source`. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll define some variables, the first being the location of our base folder, project folder and where the annotations we receive from `CoralNet` should be stored on our local machine: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining our folder variables\n",
        "\n",
        "base_folder = '/CoralNet/' \n",
        "project_folder = 'ARMS'\n",
        "output_folder = 'JSON_files\\\\' "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go ahead and place your dropbox token in the string variable below (it may be the same length or longer depending on if you chose a temporary token). Next we have a variable to access the dropbox account using said token. This cell should spit out some information about your `dropbox` account if the token is correct, otherwise it will throw an error."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dropbox_token = 'Your Dropbox Token Here'\n",
        "\n",
        "# Connects to our Dropbox account\n",
        "dbx = dropbox.Dropbox(dropbox_token)\n",
        "dbx.users_get_current_account()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have access to our `dropbox` account through the application, we need to gain access to our `CoralNet` account. Go ahead and enter your username and password into the `payload` dictionary (don't worry, I won't steal it). If the username and password are correct, you should see the CoralNet token printed out as a string of letters and numbers."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "url     = 'https://coralnet.ucsd.edu/api/token_auth/'\n",
        "payload = '{ \"username\" : \"Your Username Here\", \"password\" : \"Your Password Here\"}'\n",
        "headers = {\"Content-type\" : \"application/vnd.api+json\"}\n",
        "coralnet_token = requests.post(url, data = payload, headers = headers).text.split(':\"')[-1][:-2]\n",
        "\n",
        "print(coralnet_token)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next you'll want to enter the source ID that you're interested in using into the `source_id` variable. If you don't know what the source ID is, check out this [link](https://coralnet.ucsd.edu/pages/help/api/tutorials/). \n",
        "\n",
        "As shown in `CoralNet`'s tutorial, you can find the source ID by going to your source page (or any that is publically avaliable), looking at the classification chart, and hovering your mouse over the any of the points on the line-graph:\n",
        "\n",
        "![alt text](Figures/classifier_overview.png \"classifier overview\")\n",
        "\n",
        "the source ID is written as the `Global ID` at the bottom of the pop-up box. Take this value and place it in the `source_id` variable below. For example, the source I plan to use is `12475`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# The URL of the source that will be used to annotate images\n",
        "\n",
        "source_id = '12475'\n",
        "classifier_url = 'https://coralnet.ucsd.edu/api/classifier/' + source_id + '/deploy/' \n",
        "\n",
        "# Saves the classifier URL you will be using and your CoralNet authorization token\n",
        "headers = {\"Authorization\": f\"Token {coralnet_token}\", \n",
        "           \"Content-type\": \"application/vnd.api+json\"}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we'll create a list of all of the images that are currently in the dropbox `project_folder`. You can see below that we create a list called `file_list` and in it we store just a single image, which includes all of the metadata from dropbox. Note that you can increase the number of images you want to be annotated by the source by changing the `num_images` variable."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = 3\n",
        "\n",
        "# Stores the image file names currently in dropbox folder\n",
        "file_list = []\n",
        "\n",
        "# Pulls out first N (limit) image files from folder\n",
        "files = dbx.files_list_folder(f'{base_folder}{project_folder}', limit = num_images)\n",
        "file_list.extend(files.entries)\n",
        "\n",
        "print(\"Number of files collected:\", len(file_list), \"\\n\")\n",
        "print(file_list[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specifying the Points to be Annotated\n",
        "Now, if you're familiar with Coral Point Count (CPCe) annotations, then you'll know that you can set the points to be annotated either randomly all over the image, randomly within a specific grid formation, or completely uniformly in a grid formation. For this tutorial I prefer to do the later, but you can decide for yourself how you want to do it. \n",
        "\n",
        "I wrote a very simple function that will take in the shape of the image and the percentage of pixels I want to be annotated. For example, my images are about 6000 x 6000 pixels and I can decide what % of the pixels in the image I want annotated. Note that `CoralNet` only allows a maximum of `200` points per request. So if you need more than `200`, you'll have to make multiple requests for the same image.\n",
        "\n",
        "Here I just chose .06% of all of the pixels, and create an offset of 2% for the height and width of the image because they have slightly different dimensions. Because of this, I actually load all of my images locally first just to get their dimensions so I can set the offset. However, if all of your images are the same size then you don't need to worry about that and the offset values can be fixed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting one of my images locally\n",
        "img_files = glob.glob(\"Data\\\\images\\\\*.jpg\")\n",
        "img = plt.imread(img_files[0])\n",
        "\n",
        "# Setting the parameter values\n",
        "height, width = img.shape[0:2]\n",
        "h_offset = int(.02 * height)\n",
        "w_offset = int(.02 * width)\n",
        "percentage = .000575\n",
        "sampling_method = 'grid'\n",
        "per_image = 1\n",
        "\n",
        "print(\"Number of points:\", int(height * width * percentage * .01))\n",
        "print(\"Offsets (height, width):\", h_offset, w_offset)\n",
        "\n",
        "# Getting the points\n",
        "points = get_points(height, width, h_offset, w_offset, percentage, sampling_method)\n",
        "\n",
        "# Converting from dictionary to list to be viewed\n",
        "points_ = [[point['column'], point['row']] for point in points]\n",
        "points_ = np.array(points_).T\n",
        "\n",
        "# Plotting the image and points to be annotated\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.imshow(img)\n",
        "plt.scatter(points_[0], points_[1])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "For me, this a good amount of points, but if you wanted to increase them feel free to do so. I will warn that the `CoralNet` website might not be able to handle too many points, so start out small (again, < 200).\n",
        "\n",
        "Now that we know how our image is going to be annotated, lets put it into action by creating a JSON file that contains this information that we'll then send to the `source` as a request!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Our data dictionary\n",
        "data = {\"data\":[]}\n",
        "\n",
        "# Looping through the list of files in dropbox\n",
        "for _, entry in enumerate(file_list):\n",
        "    \n",
        "    # This section can be ignored if your images are of the same dimensions\n",
        "    # otherwise, you can do something similar, where you open the same images\n",
        "    # locally, check the dimensions, and set the offsets as you desire.\n",
        "    assert entry.name == img_files[_].split(\"\\\\\")[-1], print(\"Files not matching\")\n",
        "    \n",
        "    img = Image.open(img_files[_])\n",
        "    width, height = img.size\n",
        "    h_offset = int(.02 * height)\n",
        "    w_offset = int(.02 * width)\n",
        "    \n",
        "    # For each file in the dropbox:\n",
        "    # set the Local address and URL dropbox address to the image file;\n",
        "    # make the URL shareable by swapping '0' with '1';\n",
        "    # get the points to be annotated based on the parameters provided;\n",
        "    # add that to our data dictionary.\n",
        "    for __ in range(per_image):\n",
        "    \n",
        "        local_address = f'{base_folder}{project_folder}/' + entry.name\n",
        "        URL_address = dbx.sharing_create_shared_link(path = local_address, short_url = False, pending_upload = None)\n",
        "        URL_address.url = URL_address.url[ : -1] + '1'\n",
        "\n",
        "        get_points(height, width, h_offset, w_offset, percentage, sampling_method)\n",
        "\n",
        "        point_locations = {\"type\" : \"image\", \n",
        "                           \"attributes\": {\"url\" : URL_address.url, \n",
        "                                          \"points\": points\n",
        "                                      }\n",
        "                                  }\n",
        "\n",
        "        data['data'].append(point_locations)\n",
        "\n",
        "# Once we've gone through all of our images, export our JSON request locally\n",
        "with open(f'{output_folder}{project_folder}_Full_Request.json', 'w') as outfile:\n",
        "    json.dump(data, outfile)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that we have three entries in our JSON request file:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "len(data['data'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requesting Annotations from the `Source`\n",
        "\n",
        "So now we can actually make the request! This involves looping through each entry in our JSON request file, changing the format to match what the API requires, sending the request and then...waiting! The `source` is not able to process the information we provide immediately, in fact, the larger the images and the more points you want annotated, the longer it takes. Apparently `CoralNet` will be upgrading their system in the near future (sometime in 2021), but until then you'll just have to be patient and let the `source` work it's magic (even if that means leaving your computer running over-night).\n",
        "\n",
        "Before we start, we can create a little function that houses are status checker. After we send a request we have to wait. But how will we know when the `source` is done and we can collect our annotated points? We send a request for a status update of course! When we ask for an update, `CoralNet` will send us a small amount of information telling us how our `source` is doing. That's what `check_status` decodes.\n",
        "\n",
        "Then we have `convert_to_csv`, this will take the annotations sent back from the `source` and convert them into a `csv` file. For each image we'll have a csv file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def check_status(r):\n",
        "    \n",
        "    # Sends a request to retrieve the completed annotations, obtains status update\n",
        "    r_status = requests.get(url = 'https://coralnet.ucsd.edu' + r.headers['Location'], \n",
        "                            headers = {\"Authorization\": f\"Token {coralnet_token}\"})\n",
        "\n",
        "    # Extracts the content from the status update\n",
        "    curr_status, message = decode_status(r_status)\n",
        "        \n",
        "    return curr_status, message    \n",
        "\n",
        "\n",
        "def convert_to_csv(export):\n",
        "    \n",
        "    all_preds = pd.DataFrame()\n",
        "\n",
        "    image_file = export['data'][0]['id'].split(\"/\")[-1].split(\"?\")[0]\n",
        "\n",
        "    for point in export['data'][0]['attributes']['points']:\n",
        "\n",
        "        per_point = dict()\n",
        "\n",
        "        per_point['image'] = image_file\n",
        "\n",
        "        per_point['X'] = point['column']\n",
        "        per_point['Y'] = point['row']\n",
        "\n",
        "        for index, classification in enumerate(point['classifications']):\n",
        "\n",
        "            per_point['score_' + str(index + 1)] = classification['score']\n",
        "            per_point['label_id_' + str(index + 1)] = classification['label_id']\n",
        "            per_point['label_code_' + str(index + 1)] = classification['label_code']\n",
        "            per_point['label_name_' + str(index + 1)] = classification['label_name']\n",
        "\n",
        "        all_preds = pd.concat([all_preds, pd.DataFrame.from_dict([per_point])])\n",
        "    \n",
        "    return all_preds"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each file we want annotated, we'll provide an entry inside of `export` to hold that information"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "export = {\"data\": []}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we loop through our original JSON request file, send each individual entry (i.e., image file) as a request to the `source`. Currently this is setup to run one request at a time, however, `CoralNet` allows up to five. If you require higher throughput, please feel free to change as needed.\n",
        "\n",
        "After a request is sent and the source has finished its annotations, we'll receive that information and store it in `exports`, and also create those csv files."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# How long to wait before asking for another status update\n",
        "patience = 60\n",
        "\n",
        "# Looping through each file\n",
        "for _ in range(len(data['data'])):\n",
        "    \n",
        "    # For feedback purposes\n",
        "    reported = False\n",
        "    \n",
        "    # Break the data into batches of N (CoralNet requirement)\n",
        "    current_batch = {\"data\" : data['data'][_ : _ + 1]}\n",
        "    \n",
        "    # Creates an individual request from our JSON request file\n",
        "    with open(f'{output_folder}Batch_{str(_+1)}.json', 'w') as outfile:\n",
        "        json.dump(current_batch, outfile)\n",
        "    \n",
        "    print(\"\\nCurrently on batch:\", str(_ + 1), \" containing:\", len(current_batch['data']), \" entries.\")\n",
        "\n",
        "    # Sends the requests to the `source` and in exchange we recieve a message telling us if it was recieved correctly.\n",
        "    r = requests.post(url = classifier_url, data = open(f\"{output_folder}Batch_{str(_+1)}.json\"), headers = headers) \n",
        "    \n",
        "    # If request didn't go through, end the loop and change the settings according to the error\n",
        "    if(r.content.decode() != ''):\n",
        "        print(\"Error: \", r, r.content)\n",
        "        break\n",
        "    else:\n",
        "        print(\"Request sent successfully! Please wait\", patience, \"seconds\")\n",
        "\n",
        "    # Waits N seconds before attempting to retrieve results\n",
        "    time.sleep(patience)     \n",
        "    in_progress = True\n",
        "    \n",
        "    # Pings CoralNet every N seconds to check the status of the job\n",
        "    while in_progress:\n",
        "        \n",
        "        # Get an update on our request\n",
        "        curr_status, message = check_status(r)\n",
        "        \n",
        "        # Not complete yet, wait N seconds and then ask again\n",
        "        if message != '': \n",
        "            if(reported):\n",
        "                print('.')\n",
        "            else:\n",
        "                print(message)\n",
        "            reported = True\n",
        "            time.sleep(patience) \n",
        "        \n",
        "        # It's complete! Store the annotations in export, close while loop, goes to the next image.\n",
        "        else: \n",
        "            print(\"Finished \", str(_ + 1), \" batch\" )\n",
        "            \n",
        "            predictions = convert_to_csv(curr_status) \n",
        "            predictions.to_csv(f'{output_folder}Batch_{str(_+1)}.csv')\n",
        "            \n",
        "            export['data'].extend(curr_status['data'])\n",
        "            \n",
        "            in_progress = False"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once our requests have been met, the annotations for our images will be in `export`. We'll first save these as another JSON file for posterity. Feel free to use either the JSON files or the CSV files created during the loop for your projects!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Dumps our exported data into a JSON file\n",
        "with open(f'{output_folder}{project_folder}_Exported_Annotations.json', 'w') as outfile:\n",
        "      json.dump(export, outfile)\n",
        "\n",
        "# Saves export as a csv\n",
        "all_predictions = convert_to_csv(export)\n",
        "all_predictions.to_csv(f'{output_folder}{project_folder}_Exported_Annotations.csv')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "all_predictions.sample(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "coralnet",
      "language": "python",
      "display_name": "CoralNet"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "coralnet"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}