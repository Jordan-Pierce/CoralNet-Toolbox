{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "_This notebook is meant to demonstrate how to train a patch-based image classifier using Keras (for more tutorials please see Keras' [website](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)._ \n",
    "\n",
    "\"The CNN patch-based image classifier that was used to provide numerous additional sparse labels to each image as described in the workflow used the EfficientNet-B0 architecture. Instead of using the typical “ImageNet” weights, the classifier was initialized with the “Noisy-Student” weights, which were learned using a semi-supervised training scheme that outperformed the former (Xie et al., 2020). This encoder was followed by a max pooling operation, a dropout layer (80%), and finally a single fully connected layer with seven output nodes (one for each of the class categories). Patches were resized to 224 pixels × 224 pixels and fed to the model as training data after heavy augmentation techniques were applied using the ImgAug (Jung, 2019) library, and normalized to have pixel values between 0 and 1.\n",
    "\n",
    "The task is considered a multi-categorical classification, therefore the network used a softmax activation function resulting in an output representing the probability distribution of each potential class category. The batch size was set to 32 as this was the largest amount possible given the network architecture, the size of the image patches, and the amount of memory that could be allocated by the GPU being used. The model was trained on 10,000 image patches that were randomly split into a training (90%) and validation (10%) set for 25 epochs; the final model was evaluated using the test set that consisted of 50 manually created ground-truth dense labels (see Table 2).\n",
    "\n",
    "During training the error between the actual and predicted output was calculated using the categorical-cross entropy loss function. Parameters throughout the network were adjusted using the Adam optimizer with an initial learning rate of 10–4. During training the learning rate was reduced by a factor of 0.5 for every three epochs in which the validation loss failed to decrease, and the weights from the epoch with the lowest validation loss were archived.\"\n",
    "\n",
    "![alt text](../Figures/getting_dense_labels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, losses, metrics\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import efficientnet.keras as efn \n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels for each class category of interest used for Pierce et al., 2021\n",
    "\n",
    "class_categories = {'Branching' : 0, \n",
    "                      'Fish' : 1, \n",
    "                      'Massive' : 2,\n",
    "                      'Not Massive' : 3,\n",
    "                      'Substrate' : 4,\n",
    "                      'Target' : 5,\n",
    "                      'Water' : 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all of the patches for all of the classes created using the `patch_extractor.exe` tool\n",
    "data = glob.glob(\"Patches\\\\**\\\\*.bmp\", recursive = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split the data into a training, validation and test set. \n",
    "# Feel free to vary the ratio of the test_size parameter.\n",
    "training_files, test_files = train_test_split(data, test_size = .1)\n",
    "training_files, validation_files  = train_test_split(training_files, test_size = .1)\n",
    "\n",
    "# Patches were extracted and stored in a folder structure such that\n",
    "# all patches of a class were grouped together. This assumes that\n",
    "# the folders have the same name as the class categories.\n",
    "training_labels = [file.split(\"\\\\\")[-2] for file in training_files]\n",
    "validation_labels = [file.split(\"\\\\\")[-2] for file in validation_files]\n",
    "test_labels = [file.split(\"\\\\\")[-2] for file in test_files]\n",
    "\n",
    "# Creating a pandas dataframe for each set.\n",
    "train = pd.DataFrame(data = list(zip(training_files, training_labels)), columns = ['images', 'labels'])\n",
    "valid = pd.DataFrame(data = list(zip(validation_files, validation_labels)), columns = ['images', 'labels'])\n",
    "test = pd.DataFrame(data = list(zip(test_files, test_labels)), columns = ['images', 'labels'])\n",
    "\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation methods implemented using imgaug; training augmentations should be \n",
    "# more intense, whereas the validation and testing augmentations should be minimal to none.\n",
    "\n",
    "# Setting the amount of dropout for our model (form of data augmentation)\n",
    "dropout_rate = 0.80\n",
    "\n",
    "augs_for_train = iaa.Sequential([   iaa.Resize(224, interpolation = 'linear'),\n",
    "                          iaa.Fliplr(0.5),\n",
    "                          iaa.Flipud(0.5),\n",
    "                          iaa.Rot90([1, 2, 3, 4], True),\n",
    "                          iaa.Sometimes(.3, iaa.Affine(scale = (.95, 1.05))),\n",
    "                          iaa.Sometimes(.1, iaa.Invert(1.0)),\n",
    "                          iaa.Sometimes(.5, iaa.SomeOf((0, 1), \n",
    "                                             [\n",
    "                                                 iaa.MedianBlur(3),\n",
    "                                                 iaa.ChannelShuffle(.7),\n",
    "                                                 iaa.EdgeDetect(.5)\n",
    "                                             ])),\n",
    "\n",
    "                          iaa.Sometimes(.5, iaa.SomeOf((0, 1),\n",
    "                                            [\n",
    "                                                 iaa.Dropout(.2),\n",
    "                                                 iaa.ImpulseNoise(.2),\n",
    "                                                 iaa.SaltAndPepper(.2)\n",
    "                                            ]))\n",
    "                       ])\n",
    "\n",
    "\n",
    "augs_for_valid = iaa.Sequential([iaa.Resize(224, interpolation = 'linear')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data generators are made to take the patch file paths currentl stored in the dataframes; generators\n",
    "# create an augmentation pipeline so that patches can be read, augmented, and normalized on-the-fly \n",
    "# while training.\n",
    "\n",
    "# Batch size is dependent on the amount of memory available on your machine\n",
    "batch_size = 32\n",
    "\n",
    "# Defines the length of an epoch, all images are used\n",
    "steps_per_epoch_train = len(train)/batch_size\n",
    "steps_per_epoch_valid = len(valid)/batch_size\n",
    "\n",
    "# Learning rate \n",
    "lr = .0001\n",
    "\n",
    "# Training images are augmented, and then normalized\n",
    "train_augmentor = ImageDataGenerator(preprocessing_function = augs_for_train.augment_image,\n",
    "                                     rescale = 1.0/255.0)\n",
    "                                     \n",
    "                                                                   \n",
    "# Reading from dataframe\n",
    "train_generator = train_augmentor.flow_from_dataframe(dataframe = train, directory = None,\n",
    "                                                      x_col = 'images', y_col = 'labels', target_size = (224, 224), \n",
    "                                                      color_mode = \"rgb\",  class_mode = 'categorical', \n",
    "                                                      batch_size = batch_size, shuffle = True, seed = 42)\n",
    "                                                     \n",
    "\n",
    "# Only normalize images, no augmentation\n",
    "validate_augmentor = ImageDataGenerator( preprocessing_function = augs_for_valid.augment_image,\n",
    "                                         rescale = 1.0/255.0 )\n",
    "\n",
    "# Reading from dataframe                             \n",
    "validation_generator = validate_augmentor.flow_from_dataframe(dataframe = valid, directory = None, \n",
    "                                                              x_col = 'images', y_col = 'labels', target_size = (224, 224), \n",
    "                                                              color_mode = \"rgb\",  class_mode = 'categorical', \n",
    "                                                              batch_size = batch_size, shuffle = True, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create the model!\n",
    "# Here we load up the EfficientNet-B0 as found int he Qubvel Repo (link below) and provide the Noisy-Student weights\n",
    "# https://github.com/qubvel/efficientnet\n",
    "\n",
    "model = Sequential([\n",
    "        efn.EfficientNetB0(weights = 'noisy-student', include_top = False,  pooling = 'max'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(list(class_categories))),\n",
    "        Activation('softmax')\n",
    "])\n",
    "\n",
    "# Display the model architecture\n",
    "if True:\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Recall and Precision metric functions\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training callbacks, such as learning rate, which will reduce after two epochs by %65 if the validation loss \n",
    "# does not decrease. Only the epochs with lower validation loss values will be saved.\n",
    "\n",
    "os.makedirs(\"weights\\\\\", exist_ok=False) \n",
    "\n",
    "hollabackgirl = [\n",
    "                 ReduceLROnPlateau(monitor = 'val_loss', factor = .65, patience = 2, verbose = 1),\n",
    "                 ModelCheckpoint(filepath = 'weights\\\\model-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', \n",
    "                                 monitor='val_loss', save_weights_only = True, \n",
    "                                 save_best_only = True, verbose = 1),\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the loss function, optimizier and metrics, probably don't need to change\n",
    "# except maybe the learing rate \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = optimizers.Adam(lr = lr), \n",
    "              metrics=['acc', precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, logs the results of the training in history\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                              steps_per_epoch = steps_per_epoch_train, \n",
    "                              epochs = num_epochs, \n",
    "                              validation_data = validation_generator, \n",
    "                              validation_steps = steps_per_epoch_valid,\n",
    "                              callbacks = holla,\n",
    "                              verbose = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, loads the best weights\n",
    "model.load_weights('weights\\\\path_to_best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads from dataframe for test set\n",
    "test_generator = validate_augmentor.flow_from_dataframe(dataframe = test, \n",
    "                                                 x_col = 'images', y_col = 'labels', target_size = (224, 224), \n",
    "                                                 color_mode = \"rgb\",  class_mode = 'categorical', \n",
    "                                                 batch_size = batch_size, shuffle = False, seed = 42)\n",
    "# Defines the length of an epoch\n",
    "steps_per_epoch_test = len(test)/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides a confusion matrix of the results\n",
    "# Results, stores predictions for thresholding, shuffling needs to stay off for test\n",
    "predictions = model.predict_generator(test_generator, steps = steps_per_epoch_test)\n",
    "predict_classes = np.argmax(predictions, axis = 1)\n",
    "\n",
    "test_y = test_generator.classes\n",
    "print(\"# of images:\", len(predict_classes))\n",
    "print(accuracy_score(y_true = test_y, y_pred = predict_classes))\n",
    "print(confusion_matrix(y_true = test_y, y_pred = predict_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher values represents more sure/confident predictions\n",
    "# .1 unsure -> .5 pretty sure -> .9 very sure\n",
    "\n",
    "# Look at creating a graph of the threshold values and the accuracy\n",
    "# useful for determing how sure the model is when making predictions\n",
    "\n",
    "threshold_values = np.arange(0.0, 1.0, 0.05)\n",
    "class_ACC = []\n",
    "\n",
    "for threshold in threshold_values:\n",
    "    sure_index = []\n",
    "\n",
    "    for i in range(0, len(predictions)):\n",
    "        if( (sorted(predictions[i])[-1]) - (sorted(predictions[i])[-2]) > threshold):\n",
    "            sure_index.append(i)\n",
    "\n",
    "    sure_test_y = np.take(test_y, sure_index, axis = 0)\n",
    "    sure_pred_y = np.take(predict_classes, sure_index)\n",
    "\n",
    "    class_ACC.append(accuracy_score(sure_test_y, sure_pred_y)) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(threshold_values, class_ACC)\n",
    "plt.xlabel('Threshold Values')\n",
    "plt.xlim([0, 1])\n",
    "plt.xticks(ticks = np.arange(0, 1.05, 0.1))\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.title('Identifying the ideal threshold value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Best_Model_and_Weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
