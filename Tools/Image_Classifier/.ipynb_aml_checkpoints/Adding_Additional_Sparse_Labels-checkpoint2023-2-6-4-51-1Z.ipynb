{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "_Once the model is trained, it can be used automatically classify patches that were previously extracted (E)._\n",
    "\n",
    "\"Extracted patches were then passed to the trained classifier as input. The output for each patch was a corresponding vector representing the probability distribution of class categories to which the center-most pixel of the patch likely belonged. For each patch, the extracted location, the presumed class label, and the difference between the two highest probability distributions (i.e., top-1 and top-2 choices) were recorded.\n",
    "\n",
    "The difference between the top two probabilities was considered the relative confidence level of the classifier when making the prediction. If the difference was small, the classifier was less confident about its top-1 choice (i.e., the presumed class label). By setting a confidence threshold value, sparse labels that the classifier was less certain about could be ignored. However, determining the ideal threshold involved trying different values and comparing the classification scores of the sparse labels predicted for the test images against the labels in the corresponding pixel indices of the manually created ground-truth dense labels (i.e., test set). As is discussed in the results section, the final threshold value that was chosen was a trade-off between the total number of labels that were accepted and their classifications scores.\n",
    "\n",
    "With regards to efficiency, the CNN patch-based image classifier was able to assign roughly 200 sparse labels to an image per second, as opposed to the one annotation every 6 s that it cost users who used CPCe manually (Beijbom et al., 2015).\"\n",
    "\n",
    "![alt text](../Figures/getting_dense_labels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import get_cmap\n",
    "cm = get_cmap('jet')\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_categories = {'Branching' : 0, \n",
    "                  'Fish' : 1, \n",
    "                  'Massive' : 2,\n",
    "                  'Not Massive' : 3,\n",
    "                  'Substrate' : 4,\n",
    "                  'Target' : 5,\n",
    "                  'Water' : 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"..\\\\Figures\\\\example_coral_patch.png\"\n",
    "image_name = os.path.basename(image_file).split(\".\")[0]\n",
    "\n",
    "image = plt.imread(image_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_df = pd.read_csv(image_name + \"_Sparse_Points.csv\")\n",
    "\n",
    "patches = []\n",
    "\n",
    "for i, r in patch_df.iterrows():\n",
    "    \n",
    "    patch = plt.imread(r['file'])\n",
    "    patch = iaa.Resize(224).augment_image(image=patch) * (1./255.0)\n",
    "    patches.append(patch)\n",
    "\n",
    "patches = np.array(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the best trained model\n",
    "model = load_model(\"Best_Model_and_Weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the patches that were extracted\n",
    "predictions = model.predict(patches)\n",
    "\n",
    "# Getting the predicted labels and also the confidence score between the top two likely classes\n",
    "predicted_labels = [list(class_categories)[np.argmax(prediction, axis = 0)] for prediction in predictions]\n",
    "confidence = [sorted(prediction)[-1] - sorted(prediction)[-2] for prediction in predictions]\n",
    "\n",
    "# Adding the to the dataframe\n",
    "patch_df['Label'] = predicted_labels\n",
    "patch_df['Confidence'] = confidence\n",
    "\n",
    "# Saving again\n",
    "patch_df.to_csv(image_name + \"_Sparse_Points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just viewing the image with the sparse labels super imposed\n",
    "additional_labels = patch_df[patch_df['Confidence'] >= .70]\n",
    "\n",
    "X = additional_labels['X'].values\n",
    "Y = additional_labels['Y'].values\n",
    "C = [cm[_]/255.0 for _ in additional_labels['Labels'].values]\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.imshow(image)\n",
    "plt.scatter(X, Y, c = C)\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
