{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "import segmentation_models as sm\n",
    "from segmentation_models.losses import *\n",
    "from segmentation_models.metrics import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import imgaug.augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_codes = [\n",
    "    'Background',\n",
    "    'LC_Fol', \n",
    "    'LC_Branch', \n",
    "    'Ar_TA', \n",
    "    'LC_Por', \n",
    "    'UDC_CCA', \n",
    "    'Ro_TA', \n",
    "    'Pa_FA', \n",
    "    'Mu_Ba', \n",
    "    'CR_TA', \n",
    "    'Pa_Cy', \n",
    "    'LC_Encr', \n",
    "    'Sa_Ba', \n",
    "    'Pa_H', \n",
    "    'Pa_TA', \n",
    "    'UDC_H', \n",
    "    'CR_FA', \n",
    "    'Ro_CCA', \n",
    "    'Mu_Cy', \n",
    "    'UDC_TA', \n",
    "    'Sa_Cy', \n",
    "    'UDC_FA', \n",
    "    'Ro_H', \n",
    "    'Sa_FA', \n",
    "    'Pa_CCA', \n",
    "    'Ro_Ba', \n",
    "    'Ro_Cy', \n",
    "    'Sa_TA', \n",
    "    'Ar_Ba', \n",
    "    'UDC_Cy', \n",
    "    'Ar_FA', \n",
    "    'CR_CCA'\n",
    "]\n",
    "\n",
    "# Creating a mapping of short codes to label values\n",
    "class2label = {k:i for i, k in enumerate(short_codes)}\n",
    "\n",
    "colors = sns.color_palette('Paired', n_colors=len(short_codes))\n",
    "colors = (np.array(colors) * 255).astype(np.uint8)\n",
    "\n",
    "# Creating a mapping of label to color values\n",
    "label2color = {i: colors[i] for i, k in enumerate(short_codes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/azureuser/cloudfiles/code/Users/jordan.pierce/Data/Guam_Saipan/3653/\"\n",
    "assert os.path.exists(DATA_PATH)\n",
    "\n",
    "EXP_DIR = \"Experiments/\"\n",
    "EXP_NAME = \"112\"\n",
    "EXP_FOLDER = EXP_DIR + EXP_NAME + \"/\"\n",
    "WEIGHTS_DIR = EXP_FOLDER + \"Weights/\"\n",
    "LOGS_DIR = EXP_FOLDER + \"Logs/\"\n",
    "\n",
    "os.makedirs(EXP_DIR, exist_ok=True)\n",
    "os.makedirs(EXP_FOLDER, exist_ok=True)\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) \n",
    "os.makedirs(LOGS_DIR, exist_ok=True) \n",
    "\n",
    "label_path = DATA_PATH + \"Updated_CNet_Segmentation_Masks.csv\"\n",
    "data = pd.read_csv(label_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(data, test_size = .1)\n",
    "\n",
    "train.reset_index(drop = True, inplace = True)\n",
    "valid.reset_index(drop = True, inplace = True)\n",
    "\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorize_mask(mask):\n",
    "   \n",
    "    colored_mask = np.zeros(shape = (mask.shape[0], mask.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for _ in np.unique(mask):\n",
    "           \n",
    "            colored_mask[mask == _] = label2color[_]\n",
    "        \n",
    "    return colored_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 736, 1280 \n",
    "\n",
    "\n",
    "# Augmentation methods\n",
    "augs_for_images = iaa.Sequential([iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'linear',\n",
    "                                            random_state = 5),\n",
    "                                  iaa.Fliplr(0.25, random_state = 1),\n",
    "                                  iaa.Flipud(0.25, random_state = 2),\n",
    "                                  iaa.Rot90([1, 2, 3, 4], True, random_state = 3)\n",
    "                       ])\n",
    "\n",
    "\n",
    "augs_for_masks = iaa.Sequential([iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'nearest',\n",
    "                                           random_state = 5),\n",
    "                                  iaa.Fliplr(0.25, random_state = 1),\n",
    "                                  iaa.Flipud(0.25, random_state = 2),\n",
    "                                  iaa.Rot90([1, 2, 3, 4], True, random_state = 3)\n",
    "                                ])\n",
    "\n",
    "\n",
    "\n",
    "resize_for_images = iaa.Sequential([\n",
    "     iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'linear', random_state = 1),\n",
    "])\n",
    "\n",
    "resize_for_masks = iaa.Sequential([\n",
    "     iaa.Resize(size = {'height' : height, 'width' : width}, interpolation = 'nearest', random_state = 1),\n",
    "])\n",
    "\n",
    "\n",
    "# Image data generator class\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, dataframe, batch_size, augment, n_classes):\n",
    "        self.dataframe = dataframe\n",
    "        self.batch_size = batch_size\n",
    "        self.n_classes = n_classes\n",
    "        self.augment = augment\n",
    "          \n",
    "        \n",
    "    # Steps per epoch    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe) // self.batch_size\n",
    "    \n",
    "    # Shuffles and resets the index at the end of training epoch\n",
    "    def on_epoch_end(self):\n",
    "        self.dataframe = self.dataframe.reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    # Generates data, feeds to training\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        global preprocess_input\n",
    "        \n",
    "        processed_images = []\n",
    "        processed_masks = []\n",
    "        \n",
    "        for _ in range(self.batch_size):\n",
    "\n",
    "            the_image = plt.imread(self.dataframe['Image'][index])\n",
    "            the_mask = np.load(self.dataframe['Mask'][index]).astype('uint8')\n",
    "            one_hot_mask = to_categorical(the_mask, len(list(short_codes)))\n",
    "            \n",
    "            if(self.augment):\n",
    "                \n",
    "                processed_image = augs_for_images(image = the_image)\n",
    "                processed_mask = augs_for_masks(image = one_hot_mask)\n",
    "         \n",
    "            else:\n",
    "                # Still resizing and then random cropping, but no augmentations   \n",
    "                processed_image = resize_for_images(image = the_image)\n",
    "                processed_mask = resize_for_masks(image = one_hot_mask)\n",
    "\n",
    "            processed_images.append(preprocess_input(processed_image))\n",
    "            processed_masks.append(processed_mask)\n",
    "\n",
    "                \n",
    "        batch_x = np.array( processed_images )\n",
    "        batch_y = np.array( processed_masks )\n",
    "        \n",
    "        return (batch_x, batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for training      \n",
    "batch_size = 2\n",
    "num_epochs = 20\n",
    "\n",
    "steps_per_epoch_train = len(train) // batch_size; print(steps_per_epoch_train)\n",
    "steps_per_epoch_valid = len(valid) // batch_size; print(steps_per_epoch_valid)\n",
    "\n",
    "train_gen = DataGenerator(train, batch_size=batch_size, augment=True, n_classes=len(short_codes)) \n",
    "valid_gen = DataGenerator(valid, batch_size=batch_size, augment=False, n_classes=len(short_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'efficientnetb0'\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE) \n",
    "\n",
    "model = sm.Unet(input_shape = (None, None, 3), \n",
    "                backbone_name = BACKBONE, \n",
    "                encoder_weights = 'imagenet',\n",
    "                activation = 'softmax', \n",
    "                classes = len(list(short_codes)),\n",
    "                encoder_freeze = True,\n",
    "                decoder_use_batchnorm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [1.0 for _ in range(len(short_codes))]\n",
    "class_weights[class2label['Background']] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_loss = JaccardLoss(class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(lr = 0.001), \n",
    "              loss = [jaccard_loss], \n",
    "              metrics = ['accuracy', iou_score, precision, recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "callbacks = [\n",
    "                ReduceLROnPlateau(monitor = 'val_loss', factor = .65, patience = 2, verbose = 1),\n",
    "\n",
    "                ModelCheckpoint(filepath = WEIGHTS_DIR + 'model-{epoch:03d}.h5', \n",
    "                                monitor='val_loss', save_weights_only = True, \n",
    "                                save_best_only = False, verbose = 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator = train_gen, \n",
    "                              steps_per_epoch = steps_per_epoch_train, \n",
    "                              epochs = num_epochs, \n",
    "                              validation_data = valid_gen,\n",
    "                              validation_steps = steps_per_epoch_valid,\n",
    "                              verbose = 1,\n",
    "                              callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.argmin(history.history[\"val_loss\"]), \n",
    "         np.min(history.history[\"val_loss\"]), \n",
    "         marker = \"x\", color = \"b\", label = \"best model\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.save(EXP_FOLDER + \"Loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot(history.history[\"precision\"], label=\"precision\")\n",
    "plt.plot(history.history[\"val_precision\"], label=\"val_precision\")\n",
    "plt.title(\"Training Precision\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.save(EXP_FOLDER + \"Precision.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize= (10, 5))\n",
    "plt.plot(history.history[\"recall\"], label=\"recall\")\n",
    "plt.plot(history.history[\"val_recall\"], label=\"val_recall\")\n",
    "plt.title(\"Training Recall\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.save(EXP_FOLDER + \"Recall.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = sorted(glob.glob(WEIGHTS_DIR + \"*.h5\"), key=os.path.getmtime)\n",
    "[print(w, i) for i, w in enumerate(weights)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weights = weights[6]\n",
    "print(\"Best Weights: \", best_weights)\n",
    "model.load_weights(best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with the trained model\n",
    "\n",
    "test_gen = DataGenerator(valid, batch_size=1, augment=False, n_classes=len(short_codes))\n",
    "\n",
    "for _ in range(5):\n",
    "    \n",
    "    image, mask = test_gen.__getitem__(_) \n",
    "    prediction = model.predict(image)\n",
    "\n",
    "    mask = np.argmax(mask, axis=-1).astype(\"uint8\")\n",
    "    prediction = np.argmax(prediction, axis=-1).astype(\"uint8\")\n",
    "\n",
    "    image = image.squeeze()\n",
    "    mask = mask.squeeze()\n",
    "    prediction = prediction.squeeze()\n",
    "    \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(colorize_mask(mask))\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(colorize_mask(prediction))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coralnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "29187d11294c07bea965194f215d76d7c863eddc7d453727fd722f0612a38c27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
