# CoralNet-Toolbox ğŸª¸ğŸ§°

<div align="center">
  <p>
    <img src="https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/CoralNet_Toolbox.png" alt="CoralNet-Toolbox">
  </p>
</div>

<div align="center">

[![python-version](https://img.shields.io/pypi/pyversions/CoralNet-Toolbox.svg)](https://pypi.org/project/CoralNet-Toolbox)
[![version](https://img.shields.io/pypi/v/CoralNet-Toolbox.svg)](https://pypi.python.org/pypi/CoralNet-Toolbox)
[![pypi-passing](https://github.com/Jordan-Pierce/CoralNet-Toolbox/actions/workflows/pypi.yml/badge.svg)](https://pypi.org/project/CoralNet-Toolbox)
[![windows](https://github.com/Jordan-Pierce/CoralNet-Toolbox/actions/workflows/windows.yml/badge.svg)](https://pypi.org/project/CoralNet-Toolbox)
[![macos](https://github.com/Jordan-Pierce/CoralNet-Toolbox/actions/workflows/macos.yml/badge.svg)](https://pypi.org/project/CoralNet-Toolbox)
[![ubuntu](https://github.com/Jordan-Pierce/CoralNet-Toolbox/actions/workflows/ubuntu.yml/badge.svg)](https://pypi.org/project/CoralNet-Toolbox)
</div>

<div align="center">
  <table>
    <tr>
      <td align="center" width="33%">
        <h3>ğŸ” Annotation</h3>
        <p>Create patches, rectangles, and polygons with AI assistance</p>
      </td>
      <td align="center" width="33%">
        <h3>ğŸ§  AI-Powered</h3>
        <p>Leverage SAM, YOLOE, and various foundation models</p>
      </td>
      <td align="center" width="33%">
        <h3>ğŸš€ Complete Workflow</h3>
        <p>From data collection to model training and deployment</p>
      </td>
    </tr>
  </table>
</div>

## ğŸš¦ Quick Start

Running the following command will install the `coralnet-toolbox`, which you can then run from the command line:
```bash
# cmd

# Install
pip install coralnet-toolbox

# Run
coralnet-toolbox
```

## ğŸ“š Guides

For further instructions please see the following guides:
- [Installation](https://jordan-pierce.github.io/CoralNet-Toolbox/installation)
- [Usage](https://jordan-pierce.github.io/CoralNet-Toolbox/usage)
- [Patch-based Image Classifier](https://jordan-pierce.github.io/CoralNet-Toolbox/classify)

<details open>
  <summary><h2><b>ğŸ¥ Watch the Video Demos</b></h2></summary>
  <p align="center">
    <a href="https://youtube.com/playlist?list=PLG5z9IbwhS5NQT3B2jrg3hxQgilDeZak9&feature=shared">
      <img src="https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/toolbox_qt.PNG" alt="Video Title" width="90%">
    </a>
  </p>
</details>

## â© TL;Dr

The `CoralNet-Toolbox` is an unofficial codebase that can be used to augment processes associated with those on
[CoralNet](https://coralnet.ucsd.edu/).

It usesâœ¨[`Ultralytics`](https://github.com/ultralytics/ultralytics)ğŸš€ as a  base, which is an open-source library for
computer vision and deep learning built in `PyTorch`. For more information on their `AGPL-3.0` license, see
[here](https://github.com/ultralytics/ultralytics/blob/main/LICENSE).

### ğŸš€ Supported Models

The `toolbox` integrates a variety of state-of-the-art models to help you create rectangle and polygon annotations efficiently. Below is a categorized overview of the supported models and frameworks:

<div align="center">

| Category                | Models                                                                                       |
|-------------------------|---------------------------------------------------------------------------------------------------------|
| **Trainable**           | - ğŸ¦¾ [YOLOv3](https://docs.ultralytics.com/models/) <br> - ğŸ¦ˆ [YOLOv4](https://docs.ultralytics.com/models/) <br> - ğŸ¦… [YOLOv5](https://docs.ultralytics.com/models/) <br> - ğŸ¬ [YOLOv6](https://docs.ultralytics.com/models/) <br> - ğŸ¢ [YOLOv7](https://docs.ultralytics.com/models/) <br> - ğŸ™ [YOLOv8](https://docs.ultralytics.com/models/) <br> - ğŸ  [YOLOv9](https://docs.ultralytics.com/models/) <br> - ğŸ¦‘ [YOLOv10](https://docs.ultralytics.com/models/) <br> - ğŸš€ [YOLO11](https://docs.ultralytics.com/models/) <br> - ğŸ³ [YOLO12](https://docs.ultralytics.com/models/) |
| **Segment Anything**    | - ğŸª¸ [SAM](https://github.com/facebookresearch/segment-anything) <br> - ğŸŒŠ [CoralSCOP](https://github.com/zhengziqiang/CoralSCOP) <br> - âš¡ [FastSAM](https://github.com/CASIA-IVA-Lab/FastSAM) <br> - ğŸ” [RepViT-SAM](https://github.com/THU-MIG/RepViT) <br> - âœ‚ï¸ [EdgeSAM](https://github.com/chongzhou96/EdgeSAM) <br> - ğŸ“± [MobileSAM](https://github.com/ChaoningZhang/MobileSAM) |
| **Visual Prompting**    | - ğŸ‘ï¸ [YOLOE](https://github.com/THU-MIG/yoloe) <br> - ğŸ¤– [AutoDistill](https://github.com/autodistill): <br> &nbsp;&nbsp;&nbsp;â€¢ ğŸ¦’ Grounding DINO <br> &nbsp;&nbsp;&nbsp;â€¢ ğŸ¦‰ OWLViT <br> &nbsp;&nbsp;&nbsp;â€¢ âš¡ OmDetTurbo |

</div>

These models enable fast, accurate, and flexible annotation workflows for a wide range of use cases for patch-based image classification, object detection, instance segmentation.

## ğŸ› ï¸ Toolbox Features

<div align="center">

| ![Patch Annotation Tool](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Patches.gif)<br><sub>**Patch Annotation**</sub> | ![Rectangle Annotation Tool](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Rectangles.gif)<br><sub>**Rectangle Annotation**</sub> | ![Polygon Annotation Tool](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Polygons.gif)<br><sub>**Polygon Annotation**</sub> |
|:--:|:--:|:--:|
| ![Patch-based Image Classification](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Classification.gif)<br><sub>**Image Classification**</sub> | ![Object Detection](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Object_Detection.gif)<br><sub>**Object Detection**</sub> | ![Instance Segmentation](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Instance_Segmentation.gif)<br><sub>**Instance Segmentation**</sub> |
| ![Segment Anything Model (SAM)](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Segment_Anything.gif)<br><sub>**Segment Anything (SAM)**</sub> | ![Polygon Classification](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Classifying_Polygons.gif)<br><sub>**Polygon Classification**</sub> | ![Patch-based LAI Classification](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Classifying_Orthomosaics.gif)<br><sub>**Patch-based LAI Classification**</sub> |
| ![Cut](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Cut.gif)<br><sub>**Cut**</sub> | ![Combine](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Combine.gif)<br><sub>**Combine**</sub> | ![See Anything (YOLOE)](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/See_Anything.gif)<br><sub>**See Anything (YOLOE)**</sub> |
|  | ![Region-based Detection](https://raw.githubusercontent.com/Jordan-Pierce/CoralNet-Toolbox/refs/heads/main/figures/tools/Work_Areas.gif)<br><sub>**Region-based Detection**</sub> |  |

</div>

Enhance your CoralNet experience with these tools:
- ğŸ“¥ [Download](https://www.youtube.com/watch?v=Ds9JZATmCmw): Retrieve Source data (images and annotations) from CoralNet
- ğŸ¬ Rasters: Import images, or extract frames directly from video files
- âœï¸ Annotate: Create annotations freely
- ğŸ‘ï¸ Visualize: See CoralNet and CPCe annotations superimposed on images
- ğŸ”¬ Sample: Sample patches using various methods (Uniform, Random, Stratified)
- ğŸ§© Patches: Create patches (points)
- ğŸ”³ Rectangles: Create rectangles (bounding boxes)
- ğŸŸ£ Polygons: Create polygons (instance masks)
- âœï¸ Edit: Cut and Combine polygons and rectangles
- ğŸ¦¾ SAM: Use `FastSAM`, `CoralSCOP`, `RepViT-SAM`, `EdgeSAM`, `MobileSAM`, and `SAM` to create polygons
  - Uses [`xSAM`](https://github.com/Jordan-Pierce/xSAM)
- ğŸ‘€ YOLOE (See Anything): Detect similar appearing objects using visual prompts automatically
- ğŸ§ª AutoDistill: Use `AutoDistill` to access the following for creating rectangles and polygons:
  - Uses `Grounding DINO`, `OWLViT`, `OmDetTurbo`
- ğŸ§  Train: Build local patch-based classifiers, object detection, and instance segmentation models
- ğŸ”® Deploy: Use trained models for predictions
- ğŸ“Š Evaluation: Evaluate model performance
- ğŸš€ Optimize: Productionize models for faster inferencing
- âš™ï¸ Batch Inference: Perform predictions on multiple images, automatically
- â†”ï¸ I/O: Import and Export annotations from / to CoralNet, Viscore, and TagLab
  - Export annotations as [GeoJSONs](https://datatracker.ietf.org/doc/html/rfc7946), segmentation masks
- ğŸ“¸ YOLO: Import and Export YOLO datasets for machine learning
- ğŸ§± Tile Dataset: Tile existing Detection / Segmentation datasets
  - Uses [`yolo-tiling`](https://github.com/Jordan-Pierce/yolo-tiling)

### ğŸ“ TODO
- ğŸ¤— Model Zoo: Download `Ultralytics` models from `HuggingFace` for use in `toolbox`
- ğŸ¦Š BioCLIP, MobileCLIP (AutoDistill): Automatically classify annotations
- ğŸ“¦ [Toolshed: Access tools from the old repository](https://github.com/Jordan-Pierce/CoralNet-Toolshed)