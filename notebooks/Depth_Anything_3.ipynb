{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Depth Anything 3 (DA3) Usage Example\n",
        "\n",
        "This notebook demonstrates how to use Depth Anything 3 for camera poses and depth estimation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# !pip install depth-anything-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!uv pip install addict "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[97m[INFO ] ModelCache initialized\u001b[0m\n",
            "\u001b[93m[WARN ] Dependency `gsplat` is required for rendering 3DGS. Install via: pip install git+https://github.com/nerfstudio-project/gsplat.git@0b4dddf04cb687367602c01196913cde6a743d70\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gc\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "from depth_anything_3.api import DepthAnything3\n",
        "from depth_anything_3.utils.visualize import visualize_depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[97m[INFO ] Model cache MISS: da3nested-giant-large on cuda. Loading...\u001b[0m\n",
            "\u001b[97m[INFO ] using SwiGLU layer as FFN\u001b[0m\n",
            "\u001b[97m[INFO ] using MLP layer as FFN\u001b[0m\n",
            "\u001b[97m[INFO ] Model cached: da3nested-giant-large on cuda\u001b[0m\n",
            "\u001b[97m[INFO ] GPUInputProcessor initialized with device=cuda (NVJPEG enabled)\u001b[0m\n",
            "\u001b[97m[INFO ] Using GPUInputProcessor (NVJPEG support enabled on cuda)\u001b[0m\n",
            "Model loaded on cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DepthAnything3.from_pretrained(\"depth-anything/DA3NESTED-GIANT-LARGE-1.1\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(f\"Model loaded on {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[97m[INFO ] Processed Images Done taking 0.20669007301330566 seconds. Shape:  torch.Size([2, 3, 378, 504])\u001b[0m\n",
            "\u001b[97m[INFO ] Model Forward Pass Done. Time: 0.6087818145751953 seconds\u001b[0m\n",
            "\u001b[97m[INFO ] Conversion to Prediction Done. Time: 0.0010051727294921875 seconds\u001b[0m\n",
            "Depth shape: (2, 378, 504)\n",
            "Extrinsics: (2, 3, 4)\n",
            "Intrinsics: (2, 3, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load sample images and run inference\n",
        "image_paths = [\n",
        "    \"../data/4356/images/T_S04856.jpg\",\n",
        "    \"../data/4356/images/T_S04857.jpg\",\n",
        "    \"../data/4356/images/T_S04858.jpg\",\n",
        "    \"../data/4356/images/T_S04859.jpg\",\n",
        "]\n",
        "\n",
        "image_paths = glob.glob(\"../data/4356/images/*.jpg\")[0:2]\n",
        "\n",
        "# Run inference\n",
        "prediction = model.inference(\n",
        "    image=image_paths,\n",
        "    process_res=504,\n",
        "    process_res_method=\"upper_bound_resize\",\n",
        ")\n",
        "print(f\"Depth shape: {prediction.depth.shape}\")\n",
        "print(f\"Extrinsics: {prediction.extrinsics.shape if prediction.extrinsics is not None else 'None'}\")\n",
        "print(f\"Intrinsics: {prediction.intrinsics.shape if prediction.intrinsics is not None else 'None'}\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Prediction(depth=array([[[6.9227676, 6.8979325, 6.9349837, ..., 6.8425274, 6.902506 ,\n",
              "         6.8778615],\n",
              "        [7.1019325, 6.8394485, 6.897662 , ..., 6.8362913, 6.783809 ,\n",
              "         6.8170834],\n",
              "        [6.925881 , 6.9420166, 6.947764 , ..., 6.8219805, 6.7791815,\n",
              "         6.829266 ],\n",
              "        ...,\n",
              "        [1.321439 , 1.3202624, 1.3233435, ..., 1.4607216, 1.4608374,\n",
              "         1.461333 ],\n",
              "        [1.3264894, 1.3231192, 1.3253591, ..., 1.4556857, 1.4564066,\n",
              "         1.4570692],\n",
              "        [1.340921 , 1.326265 , 1.3282058, ..., 1.4537432, 1.4585526,\n",
              "         1.4561818]],\n",
              "\n",
              "       [[9.20652  , 9.20652  , 9.20652  , ..., 8.290206 , 8.219383 ,\n",
              "         9.20652  ],\n",
              "        [9.20652  , 9.20652  , 9.20652  , ..., 8.336343 , 8.182493 ,\n",
              "         8.241579 ],\n",
              "        [9.20652  , 9.85613  , 9.20652  , ..., 8.443877 , 9.20652  ,\n",
              "         8.367616 ],\n",
              "        ...,\n",
              "        [1.1434184, 1.1414905, 1.1425039, ..., 1.0719016, 1.0729605,\n",
              "         1.0740818],\n",
              "        [1.1389155, 1.1393204, 1.1388811, ..., 1.0663348, 1.0688909,\n",
              "         1.0682492],\n",
              "        [1.1334403, 1.13565  , 1.1361822, ..., 1.0652399, 1.0625961,\n",
              "         1.0660347]]], dtype=float32), is_metric=1, sky=None, conf=array([[[1.0000012, 1.0000002, 1.0000002, ..., 1.0005441, 1.0004714,\n",
              "         1.0010207],\n",
              "        [1.       , 1.       , 1.       , ..., 1.0000912, 1.0000749,\n",
              "         1.0001211],\n",
              "        [1.       , 1.       , 1.       , ..., 1.0001206, 1.0000646,\n",
              "         1.0002003],\n",
              "        ...,\n",
              "        [4.4209785, 4.7282114, 4.6997204, ..., 5.204621 , 5.327163 ,\n",
              "         5.093915 ],\n",
              "        [4.564371 , 4.818915 , 4.718323 , ..., 5.269451 , 5.430125 ,\n",
              "         5.353639 ],\n",
              "        [4.4015565, 4.2587175, 4.154948 , ..., 5.1802325, 5.3536453,\n",
              "         6.0480576]],\n",
              "\n",
              "       [[1.       , 1.       , 1.       , ..., 1.0000005, 1.0000005,\n",
              "         1.       ],\n",
              "        [1.       , 1.       , 1.       , ..., 1.       , 1.       ,\n",
              "         1.0000002],\n",
              "        [1.       , 1.0000001, 1.       , ..., 1.       , 1.       ,\n",
              "         1.0000002],\n",
              "        ...,\n",
              "        [5.3771152, 5.5771117, 5.540576 , ..., 5.3152347, 5.553019 ,\n",
              "         5.2994742],\n",
              "        [5.710586 , 5.7676635, 5.588507 , ..., 5.5102434, 5.7797785,\n",
              "         5.633386 ],\n",
              "        [5.471555 , 5.4106727, 5.415686 , ..., 5.35791  , 5.374189 ,\n",
              "         5.1108418]]], dtype=float32), extrinsics=array([[[ 9.9999970e-01, -6.0793744e-05,  7.4471394e-04, -3.0096069e-03],\n",
              "        [ 6.0902454e-05,  1.0000000e+00, -1.4595164e-04,  2.7018518e-04],\n",
              "        [-7.4470515e-04,  1.4599694e-04,  9.9999970e-01,  7.6476851e-04]],\n",
              "\n",
              "       [[ 9.1768813e-01, -1.7165962e-01,  3.5830358e-01, -7.5215679e-01],\n",
              "        [ 1.1491586e-01,  9.7797894e-01,  1.7421700e-01, -4.5740348e-01],\n",
              "        [-3.8031939e-01, -1.1870212e-01,  9.1720605e-01, -1.0294058e-02]]],\n",
              "      dtype=float32), intrinsics=array([[[340.77478,   0.     , 252.     ],\n",
              "        [  0.     , 348.57553, 189.     ],\n",
              "        [  0.     ,   0.     ,   1.     ]],\n",
              "\n",
              "       [[344.29562,   0.     , 252.     ],\n",
              "        [  0.     , 352.59674, 189.     ],\n",
              "        [  0.     ,   0.     ,   1.     ]]], dtype=float32), processed_images=array([[[[  1,  47,  57],\n",
              "         [  1,  48,  57],\n",
              "         [  1,  48,  55],\n",
              "         ...,\n",
              "         [  1,  97,  99],\n",
              "         [  0, 100, 102],\n",
              "         [  0,  99, 102]],\n",
              "\n",
              "        [[  1,  45,  54],\n",
              "         [  1,  47,  55],\n",
              "         [  1,  47,  54],\n",
              "         ...,\n",
              "         [  1,  98, 101],\n",
              "         [  1,  98, 100],\n",
              "         [  1,  98,  99]],\n",
              "\n",
              "        [[  0,  43,  51],\n",
              "         [  1,  44,  53],\n",
              "         [  1,  45,  53],\n",
              "         ...,\n",
              "         [  1,  98, 101],\n",
              "         [  1,  93,  98],\n",
              "         [  1,  93,  96]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 42,  70,  68],\n",
              "         [ 40,  68,  65],\n",
              "         [ 38,  67,  64],\n",
              "         ...,\n",
              "         [ 89, 165, 131],\n",
              "         [ 78, 149, 120],\n",
              "         [ 76, 145, 115]],\n",
              "\n",
              "        [[ 39,  70,  65],\n",
              "         [ 38,  69,  63],\n",
              "         [ 34,  66,  60],\n",
              "         ...,\n",
              "         [ 96, 179, 142],\n",
              "         [ 89, 166, 134],\n",
              "         [ 80, 152, 121]],\n",
              "\n",
              "        [[ 37,  72,  66],\n",
              "         [ 37,  71,  65],\n",
              "         [ 37,  68,  64],\n",
              "         ...,\n",
              "         [ 94, 176, 141],\n",
              "         [ 93, 174, 140],\n",
              "         [ 90, 166, 133]]],\n",
              "\n",
              "\n",
              "       [[[  0, 102, 124],\n",
              "         [  0, 102, 124],\n",
              "         [  0, 102, 125],\n",
              "         ...,\n",
              "         [  0, 102, 113],\n",
              "         [  0, 103, 118],\n",
              "         [  0, 103, 118]],\n",
              "\n",
              "        [[  0, 103, 124],\n",
              "         [  0, 102, 124],\n",
              "         [  0, 102, 124],\n",
              "         ...,\n",
              "         [  0,  96, 107],\n",
              "         [  0, 101, 114],\n",
              "         [  0, 103, 117]],\n",
              "\n",
              "        [[  0, 103, 124],\n",
              "         [  0, 102, 124],\n",
              "         [  0, 102, 124],\n",
              "         ...,\n",
              "         [  0,  99, 112],\n",
              "         [  0, 103, 117],\n",
              "         [  0, 104, 117]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 91, 171, 146],\n",
              "         [ 92, 172, 145],\n",
              "         [ 94, 174, 144],\n",
              "         ...,\n",
              "         [ 78, 136, 105],\n",
              "         [ 65, 120,  91],\n",
              "         [ 56, 106,  82]],\n",
              "\n",
              "        [[ 77, 152, 130],\n",
              "         [ 89, 168, 142],\n",
              "         [ 95, 176, 145],\n",
              "         ...,\n",
              "         [ 83, 144, 113],\n",
              "         [ 71, 127,  97],\n",
              "         [ 62, 114,  86]],\n",
              "\n",
              "        [[ 79, 156, 134],\n",
              "         [ 93, 175, 149],\n",
              "         [ 87, 167, 139],\n",
              "         ...,\n",
              "         [ 94, 163, 128],\n",
              "         [ 85, 149, 115],\n",
              "         [ 75, 134, 102]]]], dtype=uint8), gaussians=None, aux={}, scale_factor=1.8406522274017334)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize input images and depth maps\n",
        "n_images = len(image_paths)\n",
        "\n",
        "fig, axes = plt.subplots(2, n_images, figsize=(12, 6))\n",
        "\n",
        "if n_images == 1:\n",
        "    axes = axes.reshape(2, 1)\n",
        "\n",
        "for i in range(n_images):\n",
        "    # Show original image\n",
        "    if prediction.processed_images is not None:\n",
        "        axes[0, i].imshow(prediction.processed_images[i])\n",
        "    axes[0, i].set_title(f\"Input {i+1}\")\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Show depth map\n",
        "    depth_vis = visualize_depth(prediction.depth[i], cmap=\"Spectral\")\n",
        "    axes[1, i].imshow(depth_vis)\n",
        "    axes[1, i].set_title(f\"Depth {i+1}\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize input images and depth maps\n",
        "n_images = len(image_paths)\n",
        "\n",
        "fig, axes = plt.subplots(2, n_images, figsize=(12, 6))\n",
        "\n",
        "if n_images == 1:\n",
        "    axes = axes.reshape(2, 1)\n",
        "\n",
        "for i in range(n_images):\n",
        "    # Show original image\n",
        "    if prediction.processed_images is not None:\n",
        "        axes[0, i].imshow(prediction.processed_images[i])\n",
        "    axes[0, i].set_title(f\"Input {i+1}\")\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Show depth map\n",
        "    depth_vis = visualize_depth(prediction.depth[i], cmap=\"Spectral\")\n",
        "    axes[1, i].imshow(depth_vis)\n",
        "    axes[1, i].set_title(f\"Depth {i+1}\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction.depth[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize input images and depth maps\n",
        "n_images = len(image_paths)\n",
        "\n",
        "fig, axes = plt.subplots(2, n_images, figsize=(12, 6))\n",
        "\n",
        "if n_images == 1:\n",
        "    axes = axes.reshape(2, 1)\n",
        "\n",
        "for i in range(n_images):\n",
        "    # Show original image\n",
        "    if prediction.processed_images is not None:\n",
        "        axes[0, i].imshow(prediction.processed_images[i])\n",
        "    axes[0, i].set_title(f\"Input {i+1}\")\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Show depth map\n",
        "    depth_vis = visualize_depth(prediction.depth[i], cmap=\"Spectral\")\n",
        "    axes[1, i].imshow(depth_vis)\n",
        "    axes[1, i].set_title(f\"Depth {i+1}\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction.depth[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize input images and depth maps\n",
        "n_images = len(image_paths)\n",
        "\n",
        "fig, axes = plt.subplots(2, n_images, figsize=(12, 6))\n",
        "\n",
        "if n_images == 1:\n",
        "    axes = axes.reshape(2, 1)\n",
        "\n",
        "for i in range(n_images):\n",
        "    # Show original image\n",
        "    if prediction.processed_images is not None:\n",
        "        axes[0, i].imshow(prediction.processed_images[i])\n",
        "    axes[0, i].set_title(f\"Input {i+1}\")\n",
        "    axes[0, i].axis('off')\n",
        "    \n",
        "    # Show depth map\n",
        "    depth_vis = visualize_depth(prediction.depth[i], cmap=\"Spectral\")\n",
        "    axes[1, i].imshow(depth_vis)\n",
        "    axes[1, i].set_title(f\"Depth {i+1}\")\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction.depth[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "coralnet10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
