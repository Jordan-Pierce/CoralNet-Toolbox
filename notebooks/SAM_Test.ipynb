{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a318bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "473d4688",
   "metadata": {},
   "source": [
    "MobileSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fe7ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\zidane.jpg: 1024x1024 1 0, 404.5ms\n",
      "Speed: 6.3ms preprocess, 404.5ms inference, 22.4ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import SAM\n",
    "\n",
    "# Load the model\n",
    "model = SAM(\"mobile_sam.pt\")\n",
    "\n",
    "# Predict a segment based on a single point prompt\n",
    "model.predict(\"zidane.jpg\", points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a47965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\zidane.jpg: 1024x1024 1 0, 1 1, 1 2, 1 3, 1 4, 1 5, 1 6, 1 7, 1 8, 1 9, 1 10, 1 11, 1 12, 1 13, 1 14, 1 15, 1 16, 1 17, 1 18, 1 19, 1 20, 1 21, 1 22, 1 23, 1 24, 1 25, 1 26, 1 27, 1 28, 1 29, 1 30, 1 31, 1 32, 1 33, 1 34, 897.7ms\n",
      "Speed: 5.3ms preprocess, 897.7ms inference, 0.9ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Segment everything (if no prompts are provided?)\n",
    "model(\"zidane.jpg\")[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f652ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.235  Python-3.10.19 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 5090, 32607MiB)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.models.sam import Predictor as SAMPredictor\n",
    "\n",
    "# Create SAMPredictor\n",
    "overrides = dict(task=\"segment\", mode=\"predict\", imgsz=2048, model=\"mobile_sam.pt\")\n",
    "predictor = SAMPredictor(overrides=overrides)\n",
    "\n",
    "# Set image\n",
    "predictor.set_image(\"zidane.jpg\")  # set with image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6baa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.conf = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a5d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image\n",
    "predictor.set_image(\"zidane.jpg\")  # set with image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea64b541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\zidane.jpg: 2048x2048 1 0, 17.6ms\n",
      "Speed: 15.3ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 2048, 2048)\n",
      "Results saved to \u001b[1mC:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\runs\\segment\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\zidane.jpg: 2048x2048 1 0, 9.1ms\n",
      "Speed: 14.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 2048, 2048)\n",
      "Results saved to \u001b[1mC:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\runs\\segment\\predict\u001b[0m\n",
      "\n",
      "image 1/1 c:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\zidane.jpg: 2048x2048 1 0, 6.8ms\n",
      "Speed: 16.1ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 2048, 2048)\n",
      "Results saved to \u001b[1mC:\\Users\\jordan\\Documents\\GitHub\\CoralNet-Toolbox\\notebooks\\runs\\segment\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe85598",
   "metadata": {},
   "source": [
    "SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd244df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = SAM(\"sam_b.pt\")\n",
    "\n",
    "# Run inference with bboxes prompt\n",
    "results = model(\"zidane.jpg\", points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b75cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment everything (if no prompts are provided?)\n",
    "model(\"zidane.jpg\")[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.sam import Predictor as SAMPredictor\n",
    "\n",
    "# Create SAMPredictor\n",
    "overrides = dict(conf=0.25, task=\"segment\", mode=\"predict\", imgsz=1024, model=\"sam_b.pt\")\n",
    "predictor = SAMPredictor(overrides=overrides)\n",
    "\n",
    "# Set image\n",
    "predictor.set_image(\"zidane.jpg\")  # set with image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd237add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e942c3",
   "metadata": {},
   "source": [
    "SAM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58dc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = SAM(\"sam2.1_t.pt\")\n",
    "\n",
    "results = model(\"zidane.jpg\", points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2b54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment everything (if no prompts are provided?)\n",
    "model(\"zidane.jpg\")[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a29cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.sam import SAM2Predictor\n",
    "\n",
    "# Create SAMPredictor\n",
    "overrides = dict(conf=0.25, task=\"segment\", mode=\"predict\", imgsz=1024, model=\"sam2.1_t.pt\")\n",
    "predictor = SAM2Predictor(overrides=overrides)\n",
    "\n",
    "# Set image\n",
    "predictor.set_image(\"zidane.jpg\")  # set with image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c684c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee52c1",
   "metadata": {},
   "source": [
    "SAM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import SAM\n",
    "\n",
    "model = SAM(\"sam3.pt\")\n",
    "\n",
    "results = model(\"zidane.jpg\", points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment everything (if no prompts are provided?)\n",
    "model(\"zidane.jpg\")[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.sam import SAM3Predictor, SAM3SemanticPredictor\n",
    "\n",
    "# Create SAMPredictor\n",
    "overrides = dict(conf=0.25, task=\"segment\", mode=\"predict\", imgsz=1024, model=\"sam3.pt\")\n",
    "predictor = SAM3Predictor(overrides=overrides)\n",
    "\n",
    "# Set image\n",
    "predictor.set_image(\"zidane.jpg\")  # set with image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()\n",
    "# Run inference with single point prompt\n",
    "results = predictor(points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f820a2",
   "metadata": {},
   "source": [
    "FastSAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import FastSAM\n",
    "\n",
    "# Create a FastSAM model\n",
    "model = FastSAM(\"FastSAM-s.pt\")  # or FastSAM-x.pt\n",
    "\n",
    "source = \"zidane.jpg\"\n",
    "\n",
    "# Run inference on an image\n",
    "everything_results = model(source, device=\"cpu\", retina_masks=True, imgsz=1024, conf=0.4, iou=0.9)\n",
    "\n",
    "# Run inference with points prompt\n",
    "results = model(source, points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63259d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.models.fastsam import FastSAMPredictor\n",
    "\n",
    "# Create FastSAMPredictor\n",
    "overrides = dict(conf=0.25, task=\"segment\", mode=\"predict\", model=\"FastSAM-s.pt\", save=False, imgsz=1024)\n",
    "predictor = FastSAMPredictor(overrides=overrides)\n",
    "\n",
    "# Segment everything\n",
    "everything_results = predictor(\"zidane.jpg\")\n",
    "\n",
    "# Prompt inference\n",
    "point_results = predictor.prompt(everything_results,  points=[900, 370], labels=[1])[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b6a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coralnet10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
