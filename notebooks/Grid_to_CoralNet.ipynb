{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdce321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d971e9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\dreiss-annotations-wscnms-dropcam',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\dreiss-annotations-wscnms-usgs-auv',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\hard-mud-annotations-wscnms-dropcam',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\hard-mud-annotations-wscnms-usgs-auv',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\sand-annotations-wscnms-dropcam',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\sand-annotations-wscnms-usgs-auv',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\sav-annotations-wscnms-dropcam',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\sav-annotations-wscnms-usgs-auv',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\shell-hash-annotations-wscnms-dropcam',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\shell-hash-annotations-wscnms-usgs-auv',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\soft-mud-annotations-wscnms-dropcam',\n",
       " 'c:\\\\Users\\\\jordan\\\\Documents\\\\GitHub\\\\CoralNet-Toolbox\\\\data\\\\tator\\\\grid\\\\datasets\\\\soft-mud-annotations-wscnms-usgs-auv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_dir = os.path.abspath(\"../data/tator/grid/datasets\")\n",
    "datasets_dir\n",
    "\n",
    "datasets_folders = glob.glob(os.path.join(datasets_dir, \"*\"))\n",
    "datasets_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5c4264",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_labels = [\"Substrate 1\", \"Other benthic communities\", \"Unknown\", \"UnknownFineSediment\"]\n",
    "\n",
    "for area_factor in [0.001, 0.005, 0.01, 0.02]:  # 0.1%, 0.5%, 1%, 2%\n",
    "    cell_data_auv = []\n",
    "    cell_data_dropcam = []\n",
    "\n",
    "    for dataset_folder in datasets_folders:\n",
    "        dataset = dataset_folder\n",
    "        images = glob.glob(os.path.join(dataset, \"*.png\"))\n",
    "        json_files = glob.glob(os.path.join(dataset, \"*.json\"))\n",
    "\n",
    "        for json_file in json_files:\n",
    "            with open(json_file, 'r') as f:\n",
    "                d = json.load(f)\n",
    "                json_data = [d]\n",
    "                \n",
    "            image_name = os.path.basename(json_file).split(\"_version\")[0] + \".png\"\n",
    "            image_path = os.path.join(dataset, image_name)\n",
    "            \n",
    "            with Image.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                area = width * height\n",
    "                patch_area = area * area_factor\n",
    "                patch_size = min(int(np.sqrt(patch_area)), 336)  # Cap patch size at 336 pixels\n",
    "                \n",
    "            for j in json_data:\n",
    "                keys = j['grid'].keys()\n",
    "                for k in keys:\n",
    "                    d = j['grid'][k]\n",
    "                    for sub_key in d.keys():\n",
    "                        cell = d[sub_key]\n",
    "                        if not len(cell['labels']):\n",
    "                            continue\n",
    "                        \n",
    "                        label = cell['labels'][0]\n",
    "                        \n",
    "                        if label in ignore_labels:\n",
    "                            continue\n",
    "                        \n",
    "                        top_left_x = cell['top_left_x']\n",
    "                        top_left_y = cell['top_left_y']\n",
    "                        width = cell['width']\n",
    "                        height = cell['height']\n",
    "                        \n",
    "                        col = cell['center_x']\n",
    "                        row = cell['center_y']\n",
    "                        \n",
    "                        # Split off the \"_version*.json\" part of the filename\n",
    "                        image_name = os.path.basename(json_file).split(\"_version\")[0] + \".png\"\n",
    "                        \n",
    "                        if \"auv\" in dataset_folder.lower():\n",
    "                            cell_data_auv.append([image_name, label, col, row, patch_size])\n",
    "                        elif \"dropcam\" in dataset_folder.lower():\n",
    "                            cell_data_dropcam.append([image_name, label, col, row, patch_size])\n",
    "\n",
    "        df_auv = pd.DataFrame(cell_data_auv, columns=[\"Name\", \"Label\", \"Column\", \"Row\", \"Patch Size\"])\n",
    "        df_auv = df_auv.drop_duplicates()\n",
    "        df_auv.to_csv(f\"{datasets_dir}/auv_grid_annotations_{str(area_factor).split('.')[1]}.csv\", index=False)\n",
    "\n",
    "        df_dropcam = pd.DataFrame(cell_data_dropcam, columns=[\"Name\", \"Label\", \"Column\", \"Row\", \"Patch Size\"])\n",
    "        df_dropcam = df_dropcam.drop_duplicates()\n",
    "        df_dropcam.to_csv(f\"{datasets_dir}/dropcam_grid_annotations_{str(area_factor).split('.')[1]}.csv\", index=False)\n",
    "        \n",
    "        df_combined = pd.concat([df_auv, df_dropcam], ignore_index=True)\n",
    "        df_combined.to_csv(f\"{datasets_dir}/combined_grid_annotations_{str(area_factor).split('.')[1]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649393e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coralnet10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
