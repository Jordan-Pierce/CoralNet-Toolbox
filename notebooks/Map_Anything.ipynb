{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a76cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional config for better memory efficiency\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Required imports\n",
    "import torch\n",
    "from mapanything.models import MapAnything\n",
    "from mapanything.utils.image import load_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db7a759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained dinov2_vitg14 from torch hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jordan/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "c:\\Users\\jordan\\miniconda3\\envs\\coralnet10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1357: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:35.)\n",
      "  return t.to(\n"
     ]
    }
   ],
   "source": [
    "# Get inference device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Init model - This requires internet access or the huggingface hub cache to be pre-downloaded\n",
    "# For Apache 2.0 license model, use \"facebook/map-anything-apache\"\n",
    "model = MapAnything.from_pretrained(\"facebook/map-anything\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834dbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_write_model import read_model\n",
    "from read_write_model import extract_intrinsics_extrinsics_from_colmap\n",
    "from read_write_model import get_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681387b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded COLMAP model with 1 cameras, 68 images, 20825 points\n",
      "Extracted intrinsics shape: (68, 3, 3)\n",
      "Extracted extrinsics shape: (68, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load COLMAP model\n",
    "# The actual path to your COLMAP reconstruction directory\n",
    "colmap_path = \"../../mvat/data/D3/colmap/sparse/0\"  \n",
    "\n",
    "assert os.path.exists(colmap_path), \"COLMAP path does not exist. Please check the path.\"\n",
    "\n",
    "cameras, images, points3D = read_model(colmap_path, ext=\".txt\")  # or \".bin\"\n",
    "print(f\"Loaded COLMAP model with {len(cameras)} cameras, {len(images)} images, {len(points3D)} points\")\n",
    "\n",
    "# Extract intrinsics and extrinsics\n",
    "intrinsics, extrinsics = extract_intrinsics_extrinsics_from_colmap(cameras, images)\n",
    "print(f\"Extracted intrinsics shape: {intrinsics.shape}\")\n",
    "print(f\"Extracted extrinsics shape: {extrinsics.shape}\")\n",
    "\n",
    "# Get image paths from COLMAP images (assuming images are in the same directory or adjust paths)\n",
    "image_paths = get_image_paths(images, colmap_path)[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eacbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras, images[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df938e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images from a folder or list of paths\n",
    "images = [\n",
    "    \"../data/4356/images/T_S04856.jpg\",\n",
    "    \"../data/4356/images/T_S04857.jpg\",\n",
    "    \"../data/4356/images/T_S04858.jpg\",\n",
    "    \"../data/4356/images/T_S04859.jpg\",\n",
    "]\n",
    "\n",
    "depth_maps = [\n",
    "    \"../../mvat/data/D3/colmap/depth/T_S04856.tif\",\n",
    "    # \"../../mvat/data/D3/colmap/depth/T_S04857.tif\n",
    "    # \"../../mvat/data/D3/colmap/depth/T_S04858.tif\",\n",
    "    # \"../../mvat/data/D3/colmap/depth/T_S04859.tif\",\n",
    "]\n",
    "views = load_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "predictions = model.infer(\n",
    "    views,                            # Input views\n",
    "    memory_efficient_inference=False, # Trades off speed for more views (up to 2000 views on 140 GB)\n",
    "    use_amp=True,                     # Use mixed precision inference (recommended)\n",
    "    amp_dtype=\"bf16\",                 # bf16 inference (recommended; falls back to fp16 if bf16 not supported)\n",
    "    apply_mask=True,                  # Apply masking to dense geometry outputs\n",
    "    mask_edges=True,                  # Remove edge artifacts by using normals and depth\n",
    "    apply_confidence_mask=False,      # Filter low-confidence regions\n",
    "    confidence_percentile=10,         # Remove bottom 10 percentile confidence pixels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Access results for each view - Complete list of metric outputs\n",
    "for i, pred in enumerate(predictions):\n",
    "    # Geometry outputs\n",
    "    pts3d = pred[\"pts3d\"]                     # 3D points in world coordinates (B, H, W, 3)\n",
    "    pts3d_cam = pred[\"pts3d_cam\"]             # 3D points in camera coordinates (B, H, W, 3)\n",
    "    depth_z = pred[\"depth_z\"]                 # Z-depth in camera frame (B, H, W, 1)\n",
    "    depth_along_ray = pred[\"depth_along_ray\"] # Depth along ray in camera frame (B, H, W, 1)\n",
    "\n",
    "    # Camera outputs\n",
    "    ray_directions = pred[\"ray_directions\"]   # Ray directions in camera frame (B, H, W, 3)\n",
    "    intrinsics = pred[\"intrinsics\"]           # Recovered pinhole camera intrinsics (B, 3, 3)\n",
    "    camera_poses = pred[\"camera_poses\"]       # OpenCV (+X - Right, +Y - Down, +Z - Forward) cam2world poses in world frame (B, 4, 4)\n",
    "    cam_trans = pred[\"cam_trans\"]             # OpenCV (+X - Right, +Y - Down, +Z - Forward) cam2world translation in world frame (B, 3)\n",
    "    cam_quats = pred[\"cam_quats\"]             # OpenCV (+X - Right, +Y - Down, +Z - Forward) cam2world quaternion in world frame (B, 4)\n",
    "\n",
    "    # Quality and masking\n",
    "    confidence = pred[\"conf\"]                 # Per-pixel confidence scores (B, H, W)\n",
    "    mask = pred[\"mask\"]                       # Combined validity mask (B, H, W, 1)\n",
    "    non_ambiguous_mask = pred[\"non_ambiguous_mask\"]                # Non-ambiguous regions (B, H, W)\n",
    "    non_ambiguous_mask_logits = pred[\"non_ambiguous_mask_logits\"]  # Mask logits (B, H, W)\n",
    "\n",
    "    # Scaling\n",
    "    metric_scaling_factor = pred[\"metric_scaling_factor\"]  # Applied metric scaling (B,)\n",
    "\n",
    "    # Original input\n",
    "    img_no_norm = pred[\"img_no_norm\"]         # Denormalized input images for visualization (B, H, W, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f264d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from depth_anything_3.utils.visualize import visualize_depth\n",
    "\n",
    "# Visualize input images and depth maps\n",
    "n_images = len(predictions)\n",
    "\n",
    "fig, axes = plt.subplots(2, n_images, figsize=(12, 6))\n",
    "\n",
    "if n_images == 1:\n",
    "    axes = axes.reshape(2, 1)\n",
    "\n",
    "for i in range(n_images):\n",
    "    # Show original image\n",
    "    axes[0, i].imshow(predictions[i][\"img_no_norm\"].squeeze().cpu().numpy())\n",
    "        \n",
    "    axes[0, i].set_title(f\"Input {i+1}\")\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Show depth map\n",
    "    depth_vis = visualize_depth(predictions[i][\"depth_z\"].squeeze().cpu().numpy(), cmap=\"Spectral\")\n",
    "    axes[1, i].imshow(depth_vis)\n",
    "    axes[1, i].set_title(f\"Depth {i+1}\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b82f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['depth_z'].squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ceeb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[-1]['depth_z'].squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea152da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coralnet10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
